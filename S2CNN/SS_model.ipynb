{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import  torch \n",
    "from    torch import nn, optim, autograd\n",
    "import  numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "#import  visdom\n",
    "from    torch.nn import functional as F\n",
    "from    matplotlib import pyplot as plt\n",
    "import  random\n",
    "import os\n",
    "import torch.utils.data as Data\n",
    "from torch import Tensor\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange, Reduce\n",
    "from torchsummary import summary\n",
    "from torch.utils.checkpoint import checkpoint, checkpoint_sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "CD1_Data=np.loadtxt('cd.csv',dtype=np.float,delimiter=',')\n",
    "UV1_Data=np.loadtxt('uv.csv',dtype=np.float,delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "   ../data/91-100/S100/CD_DFT_results/100.002_sig-CD-DFT.txt not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1636420/2550875746.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mUV_Data1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/91-100/S100/UV_DFT_results/100.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"{:0>3d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_sig-UV-DFT.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtempCDData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"   ../data/91-100/S100/CD_DFT_results/100.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"{:0>3d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_sig-CD-DFT.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mtempUVData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/91-100/S100/UV_DFT_results/100.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"{:0>3d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_sig-UV-DFT.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtempCData\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../data/91-100/S100/pdb/100.\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"{:0>3d}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pdb\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows, like)\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1067\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1068\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    531\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    532\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 533\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m:    ../data/91-100/S100/CD_DFT_results/100.002_sig-CD-DFT.txt not found."
     ]
    }
   ],
   "source": [
    "for k in range(1,101):\n",
    "    if(k==1):\n",
    "        C_Data1=np.loadtxt(\"../data/91-100/S100/pdb/100.\"+\"{:0>3d}\".format(k)+\".pdb\",usecols=(5,6,7))\n",
    "        CD_Data1=np.loadtxt(\"../data/91-100/S100/CD_DFT_results/100.\"+\"{:0>3d}\".format(k)+\"_sig-CD-DFT.txt\")\n",
    "        UV_Data1=np.loadtxt(\"../data/91-100/S100/UV_DFT_results/100.\"+\"{:0>3d}\".format(k)+\"_sig-UV-DFT.txt\")\n",
    "    else:\n",
    "        tempCDData=np.loadtxt(\"   ../data/91-100/S100/CD_DFT_results/100.\"+\"{:0>3d}\".format(k)+\"_sig-CD-DFT.txt\")\n",
    "        tempUVData=np.loadtxt(\"../data/91-100/S100/UV_DFT_results/100.\"+\"{:0>3d}\".format(k)+\"_sig-UV-DFT.txt\")\n",
    "        tempCData=np.loadtxt(\"../data/91-100/S100/pdb/100.\"+\"{:0>3d}\".format(k)+\".pdb\",usecols=(5,6,7))\n",
    "        \n",
    "        C_Data1=np.append(C_Data1,tempCData,axis=0)\n",
    "        CD_Data1=np.append(CD_Data1,tempCDData,axis=0)\n",
    "        UV_Data1=np.append(UV_Data1,tempUVData,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_CD_Data=np.append(CD1_Data.reshape(9900,1,10417,2),CD_Data1.reshape(-1,1,10417,2),axis=0)\n",
    "test_UV_Data=np.append(UV1_Data.reshape(9900,1,10417,2),UV_Data1.reshape(-1,1,10417,2),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"展示用cd光谱1.csv\",test_CD_Data[3500:3505,0,:,1],delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x = y = np.arange(start=-4, stop=4, step=0.1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = 3 * (1-X)**2 * np.exp(-X**2-(Y+1)**2)- 10 * (X/5- X**3 - Y**5)*np.exp(-X**2-Y**2)-1/3*np.exp(-(X+1)**2-Y**2)\n",
    "ax.plot_surface(X,Y,Z,alpha=0.9, cstride=1, rstride = 1, cmap='rainbow')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = test_CD_Data[:10,0,:,0]\n",
    "y= np.arange(0,10,1)\n",
    "X, Y = np.meshgrid(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "x = test_CD_Data[0,0,:,0]\n",
    "y= np.arange(0,5,1)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = test_CD_Data[:5,0,:,1]\n",
    "ax.plot_surface(X,Y,Z,alpha=0.9, cstride=1, rstride = 1, cmap='rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretreatment import Pretreatment as pre\n",
    "p = pre()\n",
    "p = pre()\n",
    "\n",
    "# 该方法为快速示例 而编写 \n",
    "# 测试用例 图片名 波段起始点 波段间距\n",
    "p.PlotSpectrum(test_CD_Data[1:6,0,:,1], '演示', 0, 1.1649).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_CD_Data[:5,0,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"展示用cd光谱.csv\",test_CD_Data[1:6,0,:,1],delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Data_all=np.loadtxt(\"坐标.csv\",dtype=np.float,delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Data_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#0622新文件 划分了键长和距离的关系，前116位是验证距离关系的数据\n",
    "noh_data = np.loadtxt('../data/关联数据标注ic.csv',skiprows=1,delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "noh_y = noh_data.astype(np.float)\n",
    "print(noh_y.shape)\n",
    "a=noh_y[:,:210]\n",
    "b=noh_y[:,210:362]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.deg2rad(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dihedral_CCA.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 19)\n",
      "(10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 19)\n"
     ]
    }
   ],
   "source": [
    "#0720文件\n",
    "dihedral_CAN= np.loadtxt('../data/0720/CA-Nbond.csv',delimiter=',',dtype=np.str,encoding='gbk',skiprows=1)\n",
    "dihedral_CAN =dihedral_CAN.astype(np.float)\n",
    "print(dihedral_CAN.shape)\n",
    "dihedral_CCA= np.loadtxt('../data/0720/C-CAbond.csv',delimiter=',',dtype=np.str,encoding='gbk',skiprows=1)\n",
    "dihedral_CCA =dihedral_CCA.astype(np.float)\n",
    "print(dihedral_CCA.shape)\n",
    "dihedral_NC= np.loadtxt('../data/0720/N-Cbond.csv',delimiter=',',dtype=np.str,encoding='gbk',skiprows=1)\n",
    "dihedral_NC =dihedral_NC.astype(np.float)\n",
    "print(dihedral_NC.shape)\n",
    "dihedral_57=np.append(np.append(dihedral_CAN,dihedral_CCA,axis=1),dihedral_NC,axis=1)\n",
    "\n",
    "\n",
    "rad=np.deg2rad(dihedral_57)\n",
    "diasin=np.sin(rad)\n",
    "diacos=np.cos(rad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([[1, 2], [4, 5], [7, 8]])\n",
    "max_index = np.unravel_index(np.argmax(arr, axis=1), arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,10000,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)    # 随机数种子   随即生成的，想要固定的结果\n",
    "A = np.random.randint(10, 100, (3, 5))\n",
    "print(A)\n",
    "print(\"最大数的索引是\", np.argmax(A))  # 不加axix默认是全部\n",
    "print(\"最小数的索引是\", np.argmin(A))\n",
    "\n",
    "print(\"每一列的最大值索引：\", np.argmax(cd_inten,1).shape)\n",
    "print(\"每一行的最大值索引：\", np.argmax(uv_inten,1).shape)\n",
    "index_max=np.append(np.arange(0,10000,1).reshape(10000,1),np.argmax(cd_inten, axis=1).reshape(10000,1),1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " np.argmax(cd_inten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(cd_inten.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cd=[df.values[si] for si in index_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(np.argmax(cd_inten,1).reshape(-1,1),np.argmin(cd_inten,1).reshape(-1,1),1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"uv和cd峰值比较.csv\",np.append(max_cd.reshape(-1,1),max_uv.reshape(-1,1),1),delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cd=df.values[np.arange(0,10000,1),np.argmax(cd_inten, axis=1).reshape(10000,)]\n",
    "min_cd=df.values[np.arange(0,10000,1),np.argmin(cd_inten, axis=1).reshape(10000,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_uv=df.values[np.arange(0,10000,1),np.argmax(uv_inten, axis=1).reshape(10000,)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_pd=all_pd[1:]-all_pd[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.values.reshape(-1)[:10000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 19)\n"
     ]
    }
   ],
   "source": [
    "dihedral_data = np.loadtxt('../GAN/0627/肽键内部二面角.csv',skiprows=1,delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "dihedral_y = dihedral_data.astype(np.float)\n",
    "print(dihedral_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_index=[4601,2087,2529,4630,3038,3538,4660,4176,3927,4680,4801,6043,6599,5210,1085,546,5220,5518,5634,5720,3850,4395,5810,5077,5156,6201,2011,1568,6220,7020,7560,6490,8010,9030,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 22)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_helix[result_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"展示结果的pd.csv\",pd_20[result_index],delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"展示结果的helix.csv\",alpha_helix[result_index,2:],delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"展示结果的二面角.csv\",dihedral_y[result_index],delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_helix[2529][2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.,  4.,  7.,  7.,  7.,  7., 10.,  7., 10., 13., 10.,  8.,  7.,\n",
       "        7.,  7., 11., 12.,  8.,  7.,  4.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_20[4680]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  import sys\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000, 1)\n",
      "(10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:18: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:20: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:21: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 20)\n",
      "(10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:45: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:46: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:48: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:49: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:51: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:52: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 19)\n",
      "(10000, 19)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:56: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:57: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(10000, 18)\n",
      "(10000, 18)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:59: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:60: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(10000, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:62: DeprecationWarning: `np.str` is a deprecated alias for the builtin `str`. To silence this warning, use `str` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.str_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:63: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 111)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#0730文件\n",
    "all_pd= np.loadtxt('../data/0730/all_pd0801.csv',delimiter=',',dtype=np.str,encoding='UTF-8-sig')\n",
    "all_pd =all_pd.astype(np.float)\n",
    "print(all_pd.shape)\n",
    "\n",
    "#0812文件\n",
    "randomcoil_num= np.loadtxt('../data/0812/randomcoil_num.csv',delimiter=',',dtype=np.str,encoding='UTF-8-sig')\n",
    "randomcoil_num =randomcoil_num.astype(np.float).reshape(10000,1)\n",
    "print(randomcoil_num.shape)\n",
    "alphanum= np.loadtxt('../data/0812/alphanum.csv',delimiter=',',dtype=np.str,encoding='UTF-8-sig')\n",
    "alphanum =alphanum.astype(np.float).reshape(10000,1)\n",
    "print(alphanum.shape)\n",
    "numofalpha=np.append(randomcoil_num,alphanum,axis=1)\n",
    "\n",
    "\n",
    "#0816文件\n",
    "pd_20= np.loadtxt('../data/0816/20pd.csv',delimiter=',',dtype=np.str,encoding='UTF-8-sig')\n",
    "pd_20 =pd_20.astype(np.float)\n",
    "print(pd_20.shape)\n",
    "Radiusofgyration= np.loadtxt('../data/0816/Radiusofgyration.csv',delimiter=',',dtype=np.str,encoding='UTF-8-sig')\n",
    "Radiusofgyration =Radiusofgyration.astype(np.float).reshape(10000,1)\n",
    "print(Radiusofgyration.shape)\n",
    "\n",
    "#0812光谱点信息\n",
    "\n",
    "largest_column_count=0\n",
    "csv_file = '../data/0812/uv_inten.csv'\n",
    "with open(csv_file, 'r') as temp_f:\n",
    "    lines = temp_f.readlines()\n",
    "    for l in lines:\n",
    "        column_count = len(l.split(','))\n",
    "        largest_column_count = column_count if largest_column_count < column_count else largest_column_count\n",
    "temp_f.close()\n",
    "column_names = [i for i in range(0, largest_column_count)]\n",
    "\n",
    "uv_inten = pd.read_csv('../data/0812/uv_inten.csv', header=None, delimiter=',', names=column_names).fillna(0).values\n",
    "cd_inten = pd.read_csv('../data/0812/cd_inten.csv', header=None, delimiter=',', names=column_names).fillna(0).values\n",
    "df = pd.read_csv('../data/0812/freq.csv', header=None, delimiter=',', names=column_names)\n",
    "freq = ((df - df.min().min()) / (df.max().max() - df.min().min())).fillna(0).values\n",
    "\n",
    "test_UV_Data1=np.append(uv_inten,freq,axis=1).reshape(10000,1,2,38)\n",
    "test_CD_Data1=np.append(cd_inten,freq,axis=1).reshape(10000,1,2,38)\n",
    "\n",
    "#最近邻C原子、N原子和CA（无氢C原子）园门子\n",
    "cadist= np.loadtxt('../data/0611/Nearest_CA_distance.csv',delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "cadist_data =cadist.astype(np.float)\n",
    "print(cadist_data.shape)\n",
    "cdist= np.loadtxt('../data/0611/nearest_C_distance.csv',delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "cdist_data =cdist.astype(np.float)\n",
    "print(cdist_data.shape)\n",
    "ndist= np.loadtxt('../data/0611/nearest_N_distance.csv',delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "ndist_data =ndist.astype(np.float)\n",
    "print(ndist_data.shape)\n",
    "\n",
    "#次近邻C原子、N原子和CA（无氢C原子）原子\n",
    "ncadist= np.loadtxt('../data/0611/next-nearest-neighbor_CA_distance.csv',delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "ncadist_data =ncadist.astype(np.float)\n",
    "print(ncadist_data.shape)\n",
    "ncdist= np.loadtxt('../data/0611/next-nearest-neighbor_C_distance.csv',delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "ncdist_data =ncdist.astype(np.float)\n",
    "print(ncadist_data.shape)\n",
    "nndist= np.loadtxt('../data/0611/next-nearest-neighbor_N_distance.csv',delimiter=',',dtype=np.str,encoding='gbk',)\n",
    "nndist_data =nndist.astype(np.float)\n",
    "print(ncadist_data.shape)\n",
    "\n",
    "nearest_data=np.append(np.append(cadist_data,cdist_data,axis=1),ndist_data,axis=1)\n",
    "next_nearest_data=np.append(np.append(ncadist_data,ncdist_data,axis=1),nndist_data,axis=1)\n",
    "\n",
    "dist_data=np.append(nearest_data,next_nearest_data,axis=1)\n",
    "dist_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncadist_data.max()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/wd/anaconda3/envs/3DMC_new/lib/python3.7/site-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "coordinate_data=np.loadtxt(\"羟基C坐标.csv\",dtype=np.float,delimiter=\",\").reshape(10000,60)\n",
    "alpha_helix=np.loadtxt(\"../data/1026/alpha螺旋_汇总.CSV\",dtype=np.float,delimiter=\",\",encoding='utf-8',skiprows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5186512263511207"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1, 2, 38)\n",
      "(10000, 1, 2, 38)\n",
      "(10000, 2, 2, 38)\n",
      "(10000, 132)\n"
     ]
    }
   ],
   "source": [
    "### angle=np.append(np.append(a,b,axis=1),dihedral_57,axis=1)\n",
    "'''CD_Data=new_cd.reshape(9900,4,10417)\n",
    "UV_Data=new_uv.reshape(9900,4,10417)'''\n",
    "C_Data=np.append(np.append(dihedral_y,dist_data,axis=1),np.append(all_pd.reshape(10000,1),alpha_helix[:,:1],1),axis=1)\n",
    "#np.append(angle,dihedral_y[:9900,],axis=1)\n",
    "#data_seqx,data_seqy=create_data(C_Data,16)\n",
    "print(test_CD_Data1.shape)\n",
    "print(test_UV_Data1.shape)\n",
    "print(np.append(test_CD_Data1,test_UV_Data1,axis=1).shape)\n",
    "\"\"\"z=C_Data\n",
    "z[z>180]=360-z[z>180]\"\"\"\n",
    "\n",
    "#CD_data = np.loadtxt('../data/01-10/S01/CD_DFT_results/001.001_sig-CD-DFT.txt')\n",
    "C_data = C_Data[0]\n",
    "print(C_Data.shape)\n",
    "#210 距离和键长 152键角  57二面角  1位packing density \n",
    "raw_data=torch.from_numpy(C_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 19)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dihedral_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "x_train_maxsbs = max_abs_scaler.fit_transform(C_Data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ = max_abs_scaler.inverse_transform(x_train_maxsbs.reshape(-1,210))         # 反归一化，此时是ndarray类型的值\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Data[:,:57]==Y_[:,:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_[:,:57][1,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Data[:,:57][1,-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始光谱信息\n",
    "S_data=(np.append(test_CD_Data1[0],test_UV_Data1[0],axis=1))\n",
    "raw_spectrum=torch.from_numpy(S_data.reshape(1,2,2, 38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新的光谱提取模型输入\n",
    "x=torch.from_numpy(np.append(test_CD_Data1,test_UV_Data1,axis=1)).to(torch.float32)\n",
    "x=torch.from_numpy(test_UV_Data1).to(torch.float32)\n",
    "y=torch.from_numpy(C_Data).to(torch.float32)#直接输出坐标\n",
    "#y[:,:303]=y[:,:302]/100\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "#torch_dataset = Data.TensorDataset(x, x_dist)#输出距离\n",
    "\n",
    "train_size = int(len(torch_dataset) * 0.8)\n",
    "validate_size = int(len(torch_dataset) * 0.1)\n",
    "test_size = len(torch_dataset) - validate_size - train_size\n",
    "\n",
    "train_dataset, validate_dataset, test_dataset = torch.utils.data.random_split(torch_dataset, [train_size, validate_size, test_size],generator=torch.Generator().manual_seed(23))\n",
    "\n",
    "\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,      # 数据，封装进Data.TensorDataset()类的数据\n",
    "    batch_size=8,      # 每块的大小\n",
    "    shuffle=False,               # 要不要打乱数据 (不打乱比较好)\n",
    "    num_workers=2,              # 多进程（multiprocess）来读数据\n",
    ")\n",
    "val_loader = Data.DataLoader(\n",
    "    dataset=validate_dataset,      # 数据，封装进Data.TensorDataset()类的数据\n",
    "    batch_size=8,      # 每块的大小\n",
    "    shuffle=False,               # 要不要打乱数据 (不打乱比较好)\n",
    "    num_workers=2,              # 多进程（multiprocess）来读数据\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#新的光谱提取模型输入\n",
    "x=torch.from_numpy(np.append(test_CD_Data1,test_UV_Data1,axis=1)).to(torch.float32)\n",
    "#x=torch.from_numpy(test_CD_Data1).to(torch.float32)\n",
    "y=torch.from_numpy(x_train_maxsbs).to(torch.float32)#直接输出坐标\n",
    "#y[:,:303]=y[:,:302]/100\n",
    "train_dataset = Data.TensorDataset(x[:8000], y[:8000])\n",
    "validate_dataset = Data.TensorDataset(x[8000:9000], y[8000:9000])\n",
    "test_dataset = Data.TensorDataset(x[9000:], y[9000:])\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "\n",
    "train_size = int(len(torch_dataset) * 0.8)\n",
    "validate_size = int(len(torch_dataset) * 0.1)\n",
    "test_size = len(torch_dataset) - validate_size - train_size\n",
    "\n",
    "#train_dataset, validate_dataset, test_dataset = torch.utils.data.random_split(torch_dataset, [train_size, validate_size, test_size],generator=torch.Generator().manual_seed(23))\n",
    "\n",
    "\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=train_dataset,      # 数据，封装进Data.TensorDataset()类的数据\n",
    "    batch_size=8,      # 每块的大小\n",
    "    shuffle=False,               # 要不要打乱数据 (不打乱比较好)\n",
    "    num_workers=2,              # 多进程（multiprocess）来读数据\n",
    ")\n",
    "val_loader = Data.DataLoader(\n",
    "    dataset=validate_dataset,      # 数据，封装进Data.TensorDataset()类的数据\n",
    "    batch_size=8,      # 每块的大小\n",
    "    shuffle=False,               # 要不要打乱数据 (不打乱比较好)\n",
    "    num_workers=2,              # 多进程（multiprocess）来读数据\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testoftan=torch.deg2rad(y[:32,362:-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_Data[:,:57]>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outangle[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y[:32,362:-3:]-outangle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:32,362:-3:]==outangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:32,362:-3:][1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsin=torch.sin(testoftan)\n",
    "testcos=torch.cos(testoftan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cossin2angle(testsin,testcos):\n",
    "    testangle=torch.rad2deg(torch.arctan(testsin/testcos))\n",
    "    outangle=torch.where(testcos<0,testangle+180,testangle)\n",
    "    outangle=torch.where((testsin<0)&(testcos>0),testangle+360,outangle)\n",
    "    return outangle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cossin2angle(testsin,testcos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int = 2, patch_size: int = 1670, emb_size: int = 256, spe_size: int = 10417, patch: int = 167):\n",
    "        self.patch_size = patch_size\n",
    "        super().__init__()\n",
    "        dilation=[1,2,3]\n",
    "        self.projection1 = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            #nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=emb_size,kernel_size=(patch_size,2),stride = patch),\n",
    "            #nn.Conv1d(in_channels=in_channels,out_channels=emb_size,kernel_size=patch_size,stride=patch,dilation=dilation[0]),\n",
    "            Rearrange('b e h w -> b (h w) e'),\n",
    "        )\n",
    "        \"\"\"self.projection2 = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            #nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=emb_size,kernel_size=(patch_size,2),stride = patch),\n",
    "            #nn.Conv1d(in_channels=in_channels,out_channels=emb_size,kernel_size=patch_size,stride=patch,dilation=dilation[1]),\n",
    "            Rearrange('b e h w -> b (h w) e'),\n",
    "        )\n",
    "        self.projection3 = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            #nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=emb_size,kernel_size=(patch_size,2),stride = patch),\n",
    "            #nn.Conv1d(in_channels=in_channels,out_channels=emb_size,kernel_size=patch_size,stride=patch,dilation=dilation[2]),\n",
    "            Rearrange('b e h w -> b (h w) e'),\n",
    "        )\"\"\"\n",
    "        #self.weight=int((spe_size-dilation[0]*(patch_size-1)+1)/patch+1)+int((spe_size-dilation[1]*(patch_size-1)+1)/patch+1)+int((spe_size-dilation[2]*(patch_size-1)+1)/patch+1)\n",
    "        #print(int((spe_size-dilation[2]*(patch_size-1)+1)/patch_size+1))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "        # 位置编码信息，一共有(img_size // patch_size)**2 + 1(cls token)个位置向量\n",
    "        self.positions = nn.Parameter(torch.randn(54, emb_size))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        b, _, _,_ = x.shape\n",
    "        #print(x.shape)\n",
    "        \"\"\"x1 = self.projection1(x)\n",
    "        #print(x1.shape)\n",
    "        x2 = self.projection2(x)\n",
    "        #print(x2.shape)\n",
    "        x3 = self.projection3(x)\n",
    "        #print(x3.shape)\n",
    "        x2 = torch.cat([x1, x2], dim=1)\"\"\"\n",
    "        \n",
    "        x = self.projection1(x)\n",
    "         \n",
    "        #print(self.weight)\n",
    "        \n",
    "        #print(x.shape)\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "        # prepend the cls token to the input\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        # add position embedding\n",
    "        #print(x.shape, self.positions.shape)\n",
    "        x += self.positions\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels: int = 2, patch_size: int = 1670, emb_size: int = 256, spe_size: int = 10417, patch: int = 167):\n",
    "        self.patch_size = patch_size\n",
    "        super().__init__()\n",
    "        dilation=[1,2,3]\n",
    "        self.projection1 = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            #nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.Conv2d(in_channels=in_channels,out_channels=emb_size,kernel_size=(2,1),stride=1),\n",
    "            #nn.Conv1d(in_channels=in_channels,out_channels=emb_size,kernel_size=patch_size,stride=patch,dilation=dilation[0]),\n",
    "            Rearrange('b e h w -> b (h w) e'),\n",
    "        )\n",
    "\n",
    "      \n",
    "        #self.weight=int((spe_size-dilation[0]*(patch_size-1)+1)/patch+1)+int((spe_size-dilation[1]*(patch_size-1)+1)/patch+1)+int((spe_size-dilation[2]*(patch_size-1)+1)/patch+1)\n",
    "        #print(int((spe_size-dilation[2]*(patch_size-1)+1)/patch_size+1))\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "        # 位置编码信息，一共有(img_size // patch_size)**2 + 1(cls token)个位置向量\n",
    "        self.positions = nn.Parameter(torch.randn(39, emb_size))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x) :\n",
    "        b, _, _,_= x.shape\n",
    "        #print(x.shape)\n",
    "        \"\"\"x1 = self.projection1(x)\n",
    "        #print(x1.shape)\n",
    "        x2 = self.projection2(x)\n",
    "        #print(x2.shape)\n",
    "        x3 = self.projection3(x)\n",
    "        #print(x3.shape)\n",
    "        x2 = torch.cat([x1, x2], dim=1)\"\"\"\n",
    "        \n",
    "        x = self.projection1(x)\n",
    "         \n",
    "        #print(self.weight)\n",
    "        #print(x.shape)\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "        # prepend the cls token to the input\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        # add position embedding\n",
    "        #print(x.shape, self.positions.shape)\n",
    "        x += self.positions\n",
    "        return x\n",
    "\n",
    "\n",
    "from inspect import isfunction\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    if exists(val):\n",
    "        return val\n",
    "    return d() if isfunction(d) else d\n",
    "\n",
    "def cast_tuple(val, depth = 1):\n",
    "    return val if isinstance(val, tuple) else (val,) * depth\n",
    "\n",
    "def init_zero_(layer):\n",
    "    nn.init.constant_(layer.weight, 0.)\n",
    "    if exists(layer.bias):\n",
    "        nn.init.constant_(layer.bias, 0.)\n",
    "\n",
    "\n",
    "# helper classes\n",
    "\n",
    "class Always(nn.Module):\n",
    "    def __init__(self, val):\n",
    "        super().__init__()\n",
    "        self.val = val\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.val\n",
    "        \n",
    "        \n",
    "\n",
    "class GEGLU(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x, gates = x.chunk(2, dim = -1)\n",
    "        return x * F.gelu(gates)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        mult = 4,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim, dim * mult * 2),\n",
    "            GEGLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim * mult, dim)\n",
    "        )\n",
    "        init_zero_(self.net[-1])\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        x = self.norm(x)\n",
    "        return self.net(x)\n",
    "\n",
    "# attention\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        seq_len = None,\n",
    "        heads = 8,\n",
    "        dim_head = 64,\n",
    "        dropout = 0.,\n",
    "        gating = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        inner_dim = dim_head * heads\n",
    "        self.seq_len = seq_len\n",
    "        self.heads= heads\n",
    "        self.scale = dim_head ** -0.5\n",
    "\n",
    "        self.to_q = nn.Linear(dim, inner_dim, bias = False)\n",
    "        self.to_kv = nn.Linear(dim, inner_dim * 2, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, dim)\n",
    "\n",
    "        self.gating = nn.Linear(dim, inner_dim)\n",
    "        nn.init.constant_(self.gating.weight, 0.)\n",
    "        nn.init.constant_(self.gating.bias, 1.)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        init_zero_(self.to_out)\n",
    "\n",
    "    def forward(self, x, mask = None, attn_bias = None, context = None, context_mask = None, tie_dim = None):\n",
    "        device, orig_shape, h, has_context = x.device, x.shape, self.heads, exists(context)\n",
    "        \n",
    "        \n",
    "        context = default(context, x)\n",
    "        q, k, v = (self.to_q(x), *self.to_kv(context).chunk(2, dim = -1))\n",
    "\n",
    "        i, j = q.shape[-2], k.shape[-2]\n",
    "\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "        # scale\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        # query / key similarities\n",
    "\n",
    "        if exists(tie_dim):\n",
    "            # as in the paper, for the extra MSAs\n",
    "            # they average the queries along the rows of the MSAs\n",
    "            # they named this particular module MSAColumnGlobalAttention\n",
    "\n",
    "            q, k = map(lambda t: rearrange(t, '(b r) ... -> b r ...', r = tie_dim), (q, k))\n",
    "            q = q.mean(dim = 1)\n",
    "            \n",
    "            dots = torch.einsum('b h i d, b r h j d -> b r h i j', q, k)\n",
    "           \n",
    "            dots = rearrange(dots, 'b r ... -> (b r) ...')\n",
    "            \n",
    "        else:\n",
    "            dots = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "        # add attention bias, if supplied (for pairwise to msa attention communication)\n",
    "\n",
    "        if exists(attn_bias):\n",
    "            #print(attn_bias.shape)\n",
    "            dots = dots + attn_bias\n",
    "\n",
    "        # masking\n",
    "        \n",
    "        if exists(mask):\n",
    "            mask = default(mask, lambda: torch.ones(1, i, device = device).bool())\n",
    "            context_mask = mask if not has_context else default(context_mask, lambda: torch.ones(1, k.shape[-2], device = device).bool())\n",
    "            mask_value = -torch.finfo(dots.dtype).max\n",
    "            mask = mask[:, None, :, None] * context_mask[:, None, None, :]\n",
    "            dots = dots.masked_fill(~mask, mask_value)\n",
    "\n",
    "        # attention\n",
    "\n",
    "        attn = dots.softmax(dim = -1)\n",
    "        attn = self.dropout(attn)\n",
    "        # aggregate\n",
    "\n",
    "        out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "\n",
    "        # merge heads\n",
    "        #print('before',out)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        # gating\n",
    "        #print('before',out)\n",
    "        \"\"\"gates = self.gating(x)\n",
    "        out = out * gates.sigmoid()\"\"\"\n",
    "        #print('after',out)\n",
    "        # combine to out\n",
    "\n",
    "        out = self.to_out(out)\n",
    "        #print('after',out)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class AxialAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        heads,\n",
    "        row_attn = True,\n",
    "        col_attn = True,\n",
    "        accept_edges = False,\n",
    "        global_query_attn = False,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert not (not row_attn and not col_attn), 'row or column attention must be turned on'\n",
    "\n",
    "        self.row_attn = row_attn\n",
    "        self.col_attn = col_attn\n",
    "        self.global_query_attn = global_query_attn\n",
    "\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.attn = Attention(dim = dim, heads = heads, **kwargs)\n",
    "\n",
    "        self.edges_to_attn_bias = nn.Sequential(\n",
    "            nn.Linear(dim, heads, bias = False),\n",
    "            Rearrange('b i j h -> b h i j')\n",
    "        ) if accept_edges else None\n",
    "\n",
    "    def forward(self, x, edges = None, mask = None):\n",
    "        assert self.row_attn ^ self.col_attn, 'has to be either row or column attention, but not both'\n",
    "\n",
    "        b, h, w, d = x.shape\n",
    "        #print(x.shape)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # axial attention\n",
    "\n",
    "        if self.col_attn:\n",
    "            axial_dim = w\n",
    "            mask_fold_axial_eq = 'b h w -> (b w) h'\n",
    "            input_fold_eq = 'b h w d -> (b w) h d'\n",
    "            output_fold_eq = '(b w) h d -> b h w d'\n",
    "\n",
    "        elif self.row_attn:\n",
    "            axial_dim = h\n",
    "            mask_fold_axial_eq = 'b h w -> (b h) w'\n",
    "            input_fold_eq = 'b h w d -> (b h) w d'\n",
    "            output_fold_eq = '(b h) w d -> b h w d'\n",
    "        \n",
    "        x = rearrange(x, input_fold_eq)\n",
    "       \n",
    "        if exists(mask):\n",
    "            mask = rearrange(mask, mask_fold_axial_eq)\n",
    "\n",
    "        attn_bias = None\n",
    "        if exists(self.edges_to_attn_bias) and exists(edges):\n",
    "            \n",
    "            attn_bias = self.edges_to_attn_bias(edges)\n",
    "            \n",
    "            attn_bias = repeat(attn_bias, 'b h i j -> (b x) h i j', x = axial_dim)\n",
    "\n",
    "        tie_dim = axial_dim if self.global_query_attn else None\n",
    "        \n",
    "        out = self.attn(x, mask = mask, attn_bias = attn_bias, tie_dim = tie_dim)\n",
    "        #print(out)\n",
    "        out = rearrange(out, output_fold_eq, h = h, w = w)\n",
    "        return out\n",
    "    \n",
    "class TriangleMultiplicativeModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        hidden_dim = None,\n",
    "        mix = 'ingoing'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert mix in {'ingoing', 'outgoing'}, 'mix must be either ingoing or outgoing'\n",
    "\n",
    "        hidden_dim = default(hidden_dim, dim)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "\n",
    "        self.left_proj = nn.Linear(dim, hidden_dim)\n",
    "        self.right_proj = nn.Linear(dim, hidden_dim)\n",
    "\n",
    "        self.left_gate = nn.Linear(dim, hidden_dim)\n",
    "        self.right_gate = nn.Linear(dim, hidden_dim)\n",
    "        self.out_gate = nn.Linear(dim, hidden_dim)\n",
    "\n",
    "        # initialize all gating to be identity\n",
    "\n",
    "        for gate in (self.left_gate, self.right_gate, self.out_gate):\n",
    "            nn.init.constant_(gate.weight, 0.)\n",
    "            nn.init.constant_(gate.bias, 1.)\n",
    "\n",
    "        if mix == 'outgoing':\n",
    "            self.mix_einsum_eq = '... i k d, ... j k d -> ... i j d'\n",
    "        elif mix == 'ingoing':\n",
    "            self.mix_einsum_eq = '... k j d, ... k i d -> ... i j d'\n",
    "\n",
    "        self.to_out_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.to_out = nn.Linear(hidden_dim, dim)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        assert x.shape[1] == x.shape[2], 'feature map must be symmetrical'\n",
    "        if exists(mask):\n",
    "            mask = rearrange(mask, 'b i j -> b i j ()')\n",
    "\n",
    "        x = self.norm(x)\n",
    "      \n",
    "        left = self.left_proj(x)\n",
    "       \n",
    "        right = self.right_proj(x)\n",
    "        \n",
    "        if exists(mask):\n",
    "            left = left * mask\n",
    "            right = right * mask\n",
    "\n",
    "        left_gate = self.left_gate(x).sigmoid()\n",
    "        right_gate = self.right_gate(x).sigmoid()\n",
    "        out_gate = self.out_gate(x).sigmoid()\n",
    "        \n",
    "\n",
    "        left = left * left_gate\n",
    "        \n",
    "        right = right * right_gate\n",
    "        \n",
    "        out = torch.einsum(self.mix_einsum_eq, left, right)\n",
    "        \n",
    "        \n",
    "        out = self.to_out_norm(out)\n",
    "        out = out * out_gate\n",
    "        return self.to_out(out)\n",
    "    \n",
    "class OuterMean(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        hidden_dim = None,\n",
    "        eps = 1e-5\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        hidden_dim = default(hidden_dim, dim)\n",
    "\n",
    "        self.left_proj = nn.Linear(dim, hidden_dim)\n",
    "        self.right_proj = nn.Linear(dim, hidden_dim)\n",
    "        self.proj_out = nn.Linear(hidden_dim, dim)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        x = self.norm(x)\n",
    "        left = self.left_proj(x)\n",
    "        right = self.right_proj(x)\n",
    "        outer = rearrange(left, 'b m i d -> b m i () d') * rearrange(right, 'b m j d -> b m () j d')\n",
    "\n",
    "        if exists(mask):\n",
    "            # masked mean, if there are padding in the rows of the MSA\n",
    "            mask = rearrange(mask, 'b m i -> b m i () ()') * rearrange(mask, 'b m j -> b m () j ()')\n",
    "            outer = outer.masked_fill(~mask, 0.)\n",
    "            outer = outer.mean(dim = 1) / (mask.sum(dim = 1) + self.eps)\n",
    "        else:\n",
    "            outer = outer.mean(dim = 1)\n",
    "\n",
    "        return self.proj_out(outer)    \n",
    "\n",
    "\n",
    "class PairwiseAttentionBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        seq_len,\n",
    "        heads,\n",
    "        dim_head,\n",
    "        dropout = 0.,\n",
    "        global_column_attn = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.outer_mean = OuterMean(dim)\n",
    "\n",
    "        self.triangle_attention_outgoing = AxialAttention(dim = dim, heads = heads, dim_head = dim_head, row_attn = True, col_attn = False, accept_edges = True)\n",
    "        self.triangle_attention_ingoing = AxialAttention(dim = dim, heads = heads, dim_head = dim_head, row_attn = False, col_attn = True, accept_edges = True, global_query_attn = global_column_attn)\n",
    "        self.triangle_multiply_outgoing = TriangleMultiplicativeModule(dim = dim, mix = 'outgoing')\n",
    "        self.triangle_multiply_ingoing = TriangleMultiplicativeModule(dim = dim, mix = 'ingoing')\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        mask = None,\n",
    "        msa_repr = None,\n",
    "        msa_mask = None\n",
    "    ):\n",
    "        if exists(msa_repr):\n",
    "            x = x + self.outer_mean(msa_repr, mask = msa_mask)\n",
    "\n",
    "        x = self.triangle_multiply_outgoing(x, mask = mask) + x\n",
    "        x = self.triangle_multiply_ingoing(x, mask = mask) + x\n",
    "        x = self.triangle_attention_outgoing(x, edges = x, mask = mask) + x\n",
    "        x = self.triangle_attention_ingoing(x, edges = x, mask = mask) + x\n",
    "        return x\n",
    "    \n",
    "class MsaAttentionBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim,\n",
    "        seq_len,\n",
    "        heads,\n",
    "        dim_head,\n",
    "        dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.row_attn = AxialAttention(dim = dim, heads = heads, dim_head = dim_head, row_attn = True, col_attn = False, accept_edges = True)\n",
    "        self.col_attn = AxialAttention(dim = dim, heads = heads, dim_head = dim_head, row_attn = False, col_attn = True)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        mask = None,\n",
    "        pairwise_repr = None\n",
    "    ):\n",
    "        x = self.row_attn(x, mask = mask, edges = pairwise_repr) + x\n",
    "        x = self.col_attn(x, mask = mask) + x\n",
    "        return x\n",
    "\n",
    "# main evoformer class\n",
    "\n",
    "class EvoformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        dim,\n",
    "        seq_len,\n",
    "        heads,\n",
    "        dim_head,\n",
    "        attn_dropout,\n",
    "        ff_dropout,\n",
    "        global_column_attn = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layer = nn.ModuleList([\n",
    "            PairwiseAttentionBlock(dim = dim, seq_len = seq_len, heads = heads, dim_head = dim_head, dropout = attn_dropout, global_column_attn = global_column_attn),\n",
    "            FeedForward(dim = dim, dropout = ff_dropout),\n",
    "            MsaAttentionBlock(dim = dim, seq_len = seq_len, heads = heads, dim_head = dim_head, dropout = attn_dropout),\n",
    "            FeedForward(dim = dim, dropout = ff_dropout),\n",
    "        ])\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x, m, mask, msa_mask = inputs\n",
    "        attn, ff, msa_attn, msa_ff = self.layer\n",
    "\n",
    "        # msa attention and transition\n",
    "\n",
    "        m = msa_attn(m, mask = msa_mask, pairwise_repr = x)\n",
    "        m = msa_ff(m) + m\n",
    "\n",
    "        # pairwise attention and transition\n",
    "\n",
    "        x = attn(x, mask = mask, msa_repr = m, msa_mask = msa_mask)\n",
    "        x = ff(x) + x\n",
    "\n",
    "        return x, m, mask, msa_mask\n",
    "    \n",
    "    \n",
    "    \n",
    "class Evoformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        depth,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EvoformerBlock(**kwargs) for _ in range(depth)])\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        m,\n",
    "        mask = None,\n",
    "        msa_mask = None\n",
    "    ):\n",
    "        inp = (x, m, mask, msa_mask)\n",
    "        x, m, *_ = checkpoint_sequential(self.layers, 1, inp)\n",
    "        return x, m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test=x[:32,:,:]\n",
    "newinput=PatchEmbedding()(test)\n",
    "newinput=newinput.reshape(8,4,39,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Attention(dim=256,heads=8)(newinput.reshape(32,39,256)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairinput=OuterMean(dim=256)(newinput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PairwiseAttentionBlock(dim=256,seq_len=1024,heads=8,dim_head=64)(pairinput).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self,     \n",
    "                in_channels: int = 2,\n",
    "                patch_size: int = 1670,\n",
    "                max_seq_len: int = 2048,\n",
    "                heads: int = 8,\n",
    "                dim_head: int = 32,\n",
    "                attn_dropout: int = 0.1,\n",
    "                ff_dropout: int = 0.1,\n",
    "                emb_size: int = 128,\n",
    "                spe_size: int = 10417,\n",
    "                depth: int = 1,\n",
    "                n_classes: int = 256,\n",
    "                **kwargs):\n",
    "        super(Generator, self).__init__()\n",
    "        h_dim=512\n",
    "        self.conf_net = nn.Sequential(\n",
    "            \n",
    "            nn.Linear(906, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, 512),\n",
    "        )\n",
    "        self.patch_embedding = PatchEmbedding(in_channels, patch_size, emb_size, spe_size)\n",
    "        self.out_mean = OuterMean(dim=emb_size)\n",
    "        \n",
    "        self.template_angle_mlp=nn.Sequential(\n",
    "            nn.Linear(114, emb_size),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(emb_size, emb_size)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.net = Evoformer(\n",
    "            dim = emb_size,\n",
    "            depth = depth,\n",
    "            seq_len = max_seq_len,\n",
    "            heads = heads,\n",
    "            dim_head = dim_head,\n",
    "            attn_dropout = attn_dropout,\n",
    "            ff_dropout = ff_dropout\n",
    "        )\n",
    "\n",
    "        \"\"\"self.detailspe_net=nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            #nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.Conv2d(in_channels=2,out_channels=256,kernel_size=(100,2)),\n",
    "            \n",
    "            Rearrange('b e h w -> b   e (h w)'),\n",
    "            nn.Conv1d(in_channels=256,out_channels=32,kernel_size=100),\n",
    "            nn.MaxPool1d(50,stride=10,ceil_mode=True),\n",
    "            nn.Conv1d(in_channels=32,out_channels=1,kernel_size=100),\n",
    "    \n",
    "            nn.BatchNorm1d(1),\n",
    ")\n",
    "        \n",
    "        \n",
    "        self.concat_net=nn.Linear(919,512)\n",
    "        \"\"\"\n",
    "        self.norm = nn.LayerNorm(emb_size*39)\n",
    "        self.changedim = nn.Linear(emb_size*2,emb_size)\n",
    "        \n",
    "        self.output1_net=nn.Sequential(\n",
    "            nn.Linear(emb_size*39,256),#303代表内坐标中二面角数\n",
    "            nn.LayerNorm(256),\n",
    "            \n",
    "            nn.Linear(256,19),\n",
    "            nn.LayerNorm(19),\n",
    "\n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.output2_net=nn.Sequential(\n",
    "            nn.Linear(emb_size*39,256),#565代表2跳坐标数\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256,111),\n",
    "            nn.LayerNorm(111),\n",
    "\n",
    "        )\n",
    "        self.output3_net=nn.Sequential(\n",
    "            nn.Linear(emb_size*39,256),#565代表2跳坐标数\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256,1),\n",
    "            nn.LayerNorm(1)\n",
    "        )\n",
    "        self.output4_net=nn.Sequential(\n",
    "            nn.Linear(emb_size*39,256),#565代表2跳坐标数\n",
    "            nn.LayerNorm(256),\n",
    "            nn.Linear(256,1),\n",
    "            nn.LayerNorm(1)\n",
    "            \n",
    "        )\n",
    "     \n",
    "        self.edges_to_attn_bias = nn.Sequential(\n",
    "            nn.Linear(emb_size, heads, bias = False),\n",
    "            Rearrange('b i j h -> b h i j')\n",
    "        )\n",
    "        \n",
    "        self.attn = Attention(dim = emb_size, heads = heads, **kwargs)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, z, angle, raw_data, raw_spectrum):\n",
    "        #embedding 阶段\n",
    "        #print(z.shape)\n",
    "        #print(angle.shape)\n",
    "        signs=self.patch_embedding(z)\n",
    "        #print(signs.shape)\n",
    "        signs=signs.view(int(z.shape[0]/4),4,39,-1)\n",
    "        pairinput=self.out_mean(signs)\n",
    "        \n",
    "        \n",
    "        templates_angles=torch.cat((torch.ones(int(z.shape[0]/4),1,39,114).cuda(cuda_index),angle.view(int(z.shape[0]/4),3,1,114).repeat(1,1,39,1)),dim=1)\n",
    "        #print(templates_angles.shape)\n",
    "        t_angle_feats = self.template_angle_mlp(templates_angles)\n",
    "        msainput = torch.cat((signs, t_angle_feats), dim = 3)\n",
    "        msainput=self.changedim(msainput)\n",
    "        #print(msainput.shape)\n",
    "        #msa_mask = default(msa_mask, lambda: torch.ones_like(msa).bool())\n",
    "        #print(msainput.shape)\n",
    "        #print(pairinput.shape)\n",
    "        x, m = self.net(\n",
    "            pairinput,\n",
    "            msainput,\n",
    "            mask = None,\n",
    "            msa_mask = None\n",
    "        )\n",
    "        b, h, w, d = m.shape\n",
    "        msaembedding=rearrange(m, \"b h w d -> (b w) h d\")\n",
    "        #coor_repre=reduce(msaembedding,'b n e ->  b e', reduction='max')\n",
    "        \n",
    "        attn_bias = self.edges_to_attn_bias(m)\n",
    "        attn_bias = repeat(attn_bias, 'b h i j -> (b x) h i j', x = 39)\n",
    "        x_pre=msaembedding[:,0,:].view(-1,1,128)\n",
    "        \n",
    "      \n",
    "        #print(msaembedding.shape)\n",
    "        coor_repre = self.attn(msaembedding, context=x_pre, attn_bias = attn_bias,tie_dim = 39)\n",
    "        #print(coor_repre)\n",
    "        coor=rearrange(coor_repre, \"(b w) h d -> b h w d\",h=h,w=w)\n",
    "        ''' detail_sign=self.detailspe_net(z).view(signs.size()[0],-1)\n",
    "        detailsign=self.concat_net(detail_sign)\n",
    "        out_signs=torch.cat((signs,detailsign),1)\n",
    "        \n",
    "        \n",
    "        raw_signs = self.spe_net(raw_spectrum).repeat(signs.size()[0],1)\n",
    "        raw_detail_signs = self.detailspe_net(raw_spectrum).view(1,-1).repeat(signs.size()[0],1)\n",
    "        raw_detailsigns = self.concat_net(raw_detail_signs)\n",
    "        out_rawsigns=torch.cat((raw_signs,raw_detailsigns),1)'''\n",
    "        \n",
    "\n",
    "        #有构象\n",
    "        #output2 = self.changedim(torch.cat((out_signs,out_rawsigns),1))\n",
    "        #output1 = self.conf_net(raw_data).repeat(signs.size()[0],1)\n",
    "        #bf_out = torch.cat((output1,output2),1)\n",
    "        \n",
    "        bf_out = rearrange(coor[:,0,:], \"b w d -> b (w d)\",w=w)\n",
    "        self.norm(bf_out)\n",
    "        #print(torch.std(bf_out),torch.mean(bf_out))\n",
    "        #print(bf_out.shape)\n",
    "        anglesin=self.output1_net(bf_out)\n",
    "      \n",
    "        anglecos=self.output2_net(bf_out)\n",
    "        angle=torch.cat((anglesin,anglecos),1)\n",
    "        bondlen = self.output3_net(bf_out)\n",
    "        dist = self.output4_net(bf_out)\n",
    "        #dist=torch.sigmoid(dist)\n",
    "        \n",
    "        ordinate=torch.cat((angle,bondlen),1)\n",
    "        output=torch.cat((ordinate,dist),1)\n",
    "        \n",
    "       \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cuda_index=6\n",
    "testx=x[:32,:,:,:].cuda(cuda_index)\n",
    "confinf=y[:32,:].cuda(cuda_index)\n",
    "init_conformation = raw_data.reshape(1,117).to(torch.float32).cuda(cuda_index)\n",
    "init_spectrum = raw_spectrum.to(torch.float32).cuda(cuda_index)\n",
    "        \n",
    "dangle=confinf[:,:-3].reshape(8,4,114).cuda(cuda_index)\n",
    "output,msaembedding,x_pre,attn_bias=Generator().cuda(cuda_index)(testx,dangle[:,1:,:],init_conformation,init_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        h_dim=256\n",
    "        self.conf_net = nn.Sequential(\n",
    "            nn.Linear(135, h_dim),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, h_dim),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(h_dim, 256)\n",
    "\n",
    "        )\n",
    "        \n",
    "        self.sign_net=nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            #nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
    "            nn.Conv2d(in_channels=2,out_channels=256,kernel_size=(100,2)),\n",
    "            \n",
    "            Rearrange('b e h w -> b   e (h w)'),\n",
    "            nn.Conv1d(in_channels=256,out_channels=32,kernel_size=100),\n",
    "            nn.MaxPool1d(50,stride=10,ceil_mode=True),\n",
    "            nn.Conv1d(in_channels=32,out_channels=1,kernel_size=100),\n",
    "    \n",
    "            nn.BatchNorm1d(1),\n",
    ")\n",
    "        \n",
    "        self.changedim = nn.Linear(919,256)\n",
    "        self.output_net=nn.Sequential(\n",
    "            nn.Linear(512,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, sign, conf):\n",
    "        output1 = self.conf_net(conf)\n",
    "        output2 = self.sign_net(sign).view(-1,919)\n",
    "        output2 = self.changedim(output2)\n",
    "        bf_out = torch.cat((output1,output2),1)\n",
    "        out = self.output_net(bf_out)\n",
    "        return out.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.5)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.05)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "        \n",
    "def gradient_penalty(batchsz,D,sign, xr, xf):\n",
    "    \"\"\"\n",
    "    :param D:\n",
    "    :param xr:\n",
    "    :param xf:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    LAMBDA = 0.3\n",
    "\n",
    "    # only constrait for Discriminator\n",
    "    xf = xf.detach()\n",
    "    xr = xr.detach()\n",
    "\n",
    "    # [b, 1] => [b, 2]\n",
    "    alpha = torch.rand(batchsz, 1).cuda(cuda_index)\n",
    "    alpha = alpha.expand_as(xr)\n",
    "\n",
    "    interpolates = alpha * xr + ((1 - alpha) * xf)\n",
    "    interpolates.requires_grad_()\n",
    "\n",
    "    disc_interpolates = D(sign,interpolates)\n",
    "\n",
    "    gradients = autograd.grad(outputs=disc_interpolates, inputs=interpolates,\n",
    "                              grad_outputs=torch.ones_like(disc_interpolates),\n",
    "                              create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
    "\n",
    "    gp = ((gradients.norm(2, dim=1) - 1) ** 2).mean() * LAMBDA\n",
    "\n",
    "    return gp\n",
    "\n",
    "def coordinate_loss(x,y):\n",
    "    x=x.view(-1,304,3)\n",
    "    x_distances = torch.cdist(x,x,p=2)\n",
    "    y=y.view(-1,304,3)\n",
    "    y_distances = torch.cdist(y,y,p=2)\n",
    "    #distances = torch.cdist(t,t,p=2)\n",
    "    b_mask=mask.repeat(y.size()[0],1,1)\n",
    "    x_dist=torch.masked_select(x_distances,b_mask).view(x.size()[0],-1)\n",
    "    y_dist=torch.masked_select(y_distances,b_mask).view(y.size()[0],-1)\n",
    "    \n",
    "    #distances = torch.cdist(x_distances, y_distances, p=2)\n",
    "    l1_loss_fn = torch.nn.L1Loss(reduce=False, size_average=False)\n",
    "    return l1_loss_fn(x_dist,y_dist)\n",
    "\n",
    "def dist_loss(x,y):\n",
    "    l1_loss_fn = torch.nn.L1Loss(reduce=False, size_average=False)\n",
    "    return l1_loss_fn(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self, patience=7, verbose=False, delta=0, path='checkpoint_alphamodeleachpd_allpd5.pt', trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "            \t\t\t\t   上次验证集损失值改善后等待几个epoch\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "            \t\t\t\t\t如果是True，为每个验证集损失值改善打印一条信息\n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "            \t\t\t\t\t检测数量的最小变化，以符合改进的要求\n",
    "                           Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.\n",
    "        验证损失减少时保存模型\n",
    "        '''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        # 这里会存储迄今最优的模型\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_index=7\n",
    "indexofpre=[0,4,8,12,16]\n",
    "init_conformation = raw_data.reshape(1,132).to(torch.float32).cuda(cuda_index)\n",
    "init_spectrum = raw_spectrum[:,:1,:,:].to(torch.float32).cuda(cuda_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "path=\"checkpoint\"\n",
    "pathnum=1\n",
    "path+str(pathnum)+\"1.pt\"\n",
    "print(pathnum+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6620471477508545 0.825061559677124 0.8464376635551453 0.7418078289031983 0.23993870137441128\n",
      "0 0.6637970209121704 0.7816208801269531 0.624934740960598 0.841752655506134\n",
      "Validation loss decreased (inf --> 0.781621).  Saving model ...\n",
      "1 0.6617552042007446 0.8150615692138672 0.8256218948960304 0.722358490884304 0.24035656886006967\n",
      "2 0.6468422412872314 0.8050611019134521 0.8070631074309349 0.7034359622001648 0.2403528253880805\n",
      "3 0.6334009766578674 0.7950621843338013 0.7885055557489395 0.6848603065013885 0.24035262165845292\n",
      "3 0.6637976169586182 0.7260741419792175 0.6249353078380228 0.8117531609535217\n",
      "Validation loss decreased (0.781621 --> 0.726074).  Saving model ...\n",
      "4 0.6172391772270203 0.7850635051727295 0.769950718820095 0.6667474674582481 0.2403565637699772\n",
      "5 0.5926647186279297 0.7750648260116577 0.7514062374234199 0.649217532992363 0.2403528290919352\n",
      "6 0.5735817551612854 0.7650661468505859 0.7328728273510933 0.6320738551020623 0.24035258745083501\n",
      "6 0.6637979745864868 0.6711294817924499 0.6249356583245098 0.7817571234703063\n",
      "Validation loss decreased (0.726074 --> 0.671129).  Saving model ...\n",
      "7 0.5531213879585266 0.7550674676895142 0.7143631203770637 0.6154146305322648 0.24035534328340658\n",
      "8 0.5309693813323975 0.7450687885284424 0.6958773131370545 0.5991936668753624 0.24035258799282974\n",
      "9 0.5097441077232361 0.7350701093673706 0.6774339832663536 0.5834302216172218 0.24035534550926752\n",
      "9 0.6638026237487793 0.6167483110427856 0.6249400749467313 0.751761085987091\n",
      "Validation loss decreased (0.671129 --> 0.616748).  Saving model ...\n",
      "10 0.48622748255729675 0.7250714302062988 0.6590566024780273 0.5680572589635849 0.24035262060047047\n",
      "11 0.4689221978187561 0.715072751045227 0.6408101692795753 0.553091770708561 0.240355345900423\n",
      "12 0.45367759466171265 0.7050740718841553 0.622981154024601 0.5387494211196899 0.24035262047008535\n",
      "12 0.6637976169586182 0.5652595329284668 0.624935361340642 0.7217650485038757\n",
      "Validation loss decreased (0.616748 --> 0.565260).  Saving model ...\n",
      "13 0.44183215498924255 0.6950753927230835 0.6060783870816231 0.5247361777424813 0.24035656286185014\n",
      "14 0.43038439750671387 0.6850767135620117 0.5906938221454621 0.5109383244216442 0.24035282804326602\n",
      "15 0.4168441593647003 0.6750780344009399 0.5770240545868873 0.4974223349094391 0.24035258675420573\n",
      "15 0.6637980937957764 0.5292925968170166 0.6249357509277761 0.6917690110206604\n",
      "Validation loss decreased (0.565260 --> 0.529293).  Saving model ...\n",
      "16 0.404670774936676 0.6650793552398682 0.5645086515545845 0.48424381205439565 0.24035534339143988\n",
      "17 0.3930620551109314 0.6550806760787964 0.5515607919991017 0.47136888340115546 0.2403525880263928\n",
      "18 0.3837941884994507 0.6450819969177246 0.5387920293211937 0.4587648664414883 0.2403553441718883\n",
      "18 0.6638026237487793 0.4880730755329132 0.624940128210932 0.661772973537445\n",
      "Validation loss decreased (0.529293 --> 0.488073).  Saving model ...\n",
      "19 0.3734997808933258 0.6350833177566528 0.5262582944631576 0.4464329043328762 0.24035261941210287\n",
      "20 0.3650323450565338 0.625084638595581 0.5139266991615296 0.4344139162003994 0.24035534560612506\n",
      "21 0.35713595151901245 0.6150859594345093 0.5018542750775814 0.42267969810962674 0.24035262063772336\n",
      "21 0.6637977361679077 0.45253787040710447 0.6249354312941432 0.6317769355773926\n",
      "Validation loss decreased (0.488073 --> 0.452538).  Saving model ...\n",
      "22 0.34908396005630493 0.6050872802734375 0.49002365553379057 0.411259229183197 0.24035534502870506\n",
      "23 0.34054476022720337 0.5950886011123657 0.4783925034403801 0.40019232776761055 0.2403526203285243\n",
      "24 0.33096492290496826 0.585089921951294 0.46703483629226683 0.38954971662163734 0.2403565624185406\n",
      "24 0.6638070344924927 0.42059399127960206 0.6249443409722298 0.6017808980941772\n",
      "Validation loss decreased (0.452538 --> 0.420594).  Saving model ...\n",
      "25 0.32224228978157043 0.5750763416290283 0.4558719899654388 0.3790969822406769 0.24035282842697092\n",
      "26 0.31556668877601624 0.5650627613067627 0.44504279020428655 0.3685870051085949 0.24035258685106328\n",
      "27 0.3091087341308594 0.5550491809844971 0.43449449735879897 0.35813239246606826 0.24035534275814052\n",
      "27 0.6638028621673584 0.38960867261886595 0.6249403454437852 0.5717401878833771\n",
      "Validation loss decreased (0.420594 --> 0.389609).  Saving model ...\n",
      "28 0.303483247756958 0.5450356006622314 0.424166378736496 0.347842993080616 0.24035258760170972\n",
      "29 0.29732874035835266 0.5350220203399658 0.41402292367815974 0.33813641527295113 0.24035534383661217\n",
      "30 0.29132595658302307 0.5250084400177002 0.40407651728391647 0.3286840355694294 0.2403526202540185\n",
      "30 0.6637978553771973 0.36027994751930237 0.624935524135828 0.5416994466781616\n",
      "Validation loss decreased (0.389609 --> 0.360280).  Saving model ...\n",
      "31 0.285517156124115 0.5149948596954346 0.39440351381897926 0.31943077635765077 0.24035534479401177\n",
      "32 0.27942895889282227 0.504981279373169 0.3849204548895359 0.31033239531517026 0.240352620093831\n",
      "33 0.273864209651947 0.4949676990509033 0.3756297933757305 0.3012986894249916 0.24035534490204521\n",
      "33 0.6638025045394897 0.3325055623054504 0.6249400284327566 0.511658704996109\n",
      "Validation loss decreased (0.360280 --> 0.332506).  Saving model ...\n",
      "34 0.2687476873397827 0.4849541187286377 0.36652464875578883 0.29253434360027314 0.24035262105123062\n",
      "35 0.26323869824409485 0.47494053840637207 0.35757835575938224 0.2841485819518566 0.24035534594885177\n",
      "36 0.2581261396408081 0.46492695808410645 0.34876147520542145 0.2769297667741776 0.24035262086124085\n",
      "36 0.6637976169586182 0.30723312616348264 0.6249353520199656 0.481617963552475\n",
      "Validation loss decreased (0.332506 --> 0.307233).  Saving model ...\n",
      "37 0.25368982553482056 0.4549596309661865 0.34006810960173606 0.2708350819498301 0.24035656308350492\n",
      "38 0.24867480993270874 0.4451461434364319 0.33158633330464365 0.26496929180622103 0.24035282835060245\n",
      "39 0.24387860298156738 0.4357796609401703 0.32326474678516387 0.2576944245249033 0.24035258628109385\n",
      "39 0.6637979745864868 0.28398586082458493 0.6249357017911971 0.4524706637859344\n",
      "Validation loss decreased (0.307233 --> 0.283986).  Saving model ...\n",
      "40 0.23890861868858337 0.42718276381492615 0.31509866380691526 0.24981541550159456 0.24035534366338607\n",
      "41 0.23417820036411285 0.41906172037124634 0.30713304004073144 0.24234904454648495 0.24035258831324108\n",
      "42 0.2295728623867035 0.4112764000892639 0.2992942925989628 0.2351046126484871 0.240355344399131\n",
      "42 0.6638026237487793 0.26186352944374086 0.6249401277117431 0.42796740317344667\n",
      "Validation loss decreased (0.283986 --> 0.261864).  Saving model ...\n",
      "43 0.22476166486740112 0.4040617346763611 0.2916445662081242 0.22807762157917022 0.240352620235392\n",
      "44 0.2201603353023529 0.39724424481391907 0.2841753588914871 0.22122005040943624 0.24035534560985036\n",
      "45 0.21538540720939636 0.3908446729183197 0.2768181813657284 0.21454326575994492 0.24035262108848351\n",
      "45 0.6637977361679077 0.24027505373954772 0.6249354219734669 0.407535676240921\n",
      "Validation loss decreased (0.261864 --> 0.240275).  Saving model ...\n",
      "46 0.2106584906578064 0.38464096188545227 0.26957135982811453 0.20806757913529872 0.24035534549436635\n",
      "47 0.20496629178524017 0.3788105249404907 0.2624023834317923 0.20177221523225308 0.24035262115181347\n",
      "48 0.19924558699131012 0.3731400668621063 0.25530628380179404 0.19562625654041768 0.240356563161736\n",
      "48 0.6638070344924927 0.22049428737163543 0.6249443268831819 0.3898310704231262\n",
      "Validation loss decreased (0.240275 --> 0.220494).  Saving model ...\n",
      "49 0.19425559043884277 0.3676516115665436 0.24834312081336976 0.1896763121932745 0.24035282801905164\n",
      "50 0.18954825401306152 0.36232107877731323 0.24162671786546708 0.1838811157345772 0.2403525860054224\n",
      "51 0.1848810762166977 0.35712870955467224 0.23506938886642456 0.17824731047451498 0.24035534374534245\n",
      "51 0.6638028621673584 0.2020807945728302 0.6249403017908335 0.3738197131156921\n",
      "Validation loss decreased (0.220494 --> 0.202081).  Saving model ...\n",
      "52 0.1799272745847702 0.35200273990631104 0.22861861039698123 0.17273099015653134 0.24035258826108702\n",
      "53 0.17470185458660126 0.3469895124435425 0.22227161857485772 0.16737912943959235 0.2403553444810874\n",
      "54 0.16904951632022858 0.34206652641296387 0.21598793603479863 0.16209315690398216 0.24035261958719153\n",
      "54 0.6637977361679077 0.18453329861164092 0.6249354752376676 0.35875752997398375\n",
      "Validation loss decreased (0.202081 --> 0.184533).  Saving model ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55 0.16458702087402344 0.3372665345668793 0.20981140099465848 0.15666824369132518 0.24035534515536494\n",
      "56 0.15973888337612152 0.332565575838089 0.20378372192382813 0.1511324718594551 0.24035262106613176\n",
      "57 0.1550385057926178 0.3279404938220978 0.19786649876832962 0.1457015331685543 0.2403553454422123\n",
      "57 0.6638025045394897 0.16835484778881074 0.6249400143437087 0.34463149738311766\n",
      "Validation loss decreased (0.184533 --> 0.168355).  Saving model ...\n",
      "58 0.15021218359470367 0.3233749568462372 0.19208254823088647 0.1407118649110198 0.24035262050361295\n",
      "59 0.14565123617649078 0.31890544295310974 0.18638261687755583 0.13644946674257516 0.24035656255451368\n",
      "60 0.14193005859851837 0.3146111071109772 0.1807642981559038 0.13273959241807462 0.24035282841765768\n",
      "60 0.6638031005859375 0.1531270685195923 0.6249405175931751 0.33130211067199705\n",
      "Validation loss decreased (0.168355 --> 0.153127).  Saving model ...\n",
      "61 0.1378023326396942 0.3104170262813568 0.1753160378187895 0.12943663127720356 0.24035258686223915\n",
      "62 0.1339578628540039 0.30638638138771057 0.16999111177027226 0.12633923910558223 0.24035534300773498\n",
      "63 0.13042102754116058 0.3024806082248688 0.16479267168045045 0.12341036430746317 0.24035258752347863\n",
      "63 0.6637978553771973 0.13799920308589936 0.6249355788081884 0.31917161178588865\n",
      "Validation loss decreased (0.153127 --> 0.137999).  Saving model ...\n",
      "64 0.12645323574543 0.298574835062027 0.15966281713545322 0.12053184932470322 0.24035534384778806\n",
      "65 0.12297337502241135 0.29473677277565 0.15455177345871926 0.11770283459872008 0.24035261935622354\n",
      "66 0.11957471817731857 0.2910292446613312 0.14950011144578457 0.11491323550790548 0.2403553454012341\n",
      "66 0.6638026237487793 0.12426739263534546 0.6249400842972099 0.30772024822235106\n",
      "Validation loss decreased (0.137999 --> 0.124267).  Saving model ...\n",
      "67 0.11564259976148605 0.2874133288860321 0.1445473662316799 0.11210760253667831 0.24035262020931497\n",
      "68 0.1120649129152298 0.28379741311073303 0.13971976566314698 0.1093359167650342 0.24035534485361643\n",
      "69 0.10824482887983322 0.2803286015987396 0.1350409671664238 0.10655795719474553 0.24035262030244725\n",
      "69 0.6637976169586182 0.11198793429136276 0.6249353754594922 0.2970196051597595\n",
      "Validation loss decreased (0.124267 --> 0.111988).  Saving model ...\n",
      "70 0.10441972315311432 0.2769286334514618 0.13048766697198153 0.1037819839939475 0.24035656272215175\n",
      "71 0.10079015046358109 0.27352866530418396 0.12606805993616582 0.10100841161608697 0.24035282847353703\n",
      "72 0.09717820584774017 0.27030041813850403 0.12174195946753025 0.09822568943351508 0.24035258673557927\n",
      "72 0.6637980937957764 0.10043025994300843 0.6249357624240219 0.2869914216995239\n",
      "Validation loss decreased (0.111988 --> 0.100430).  Saving model ...\n",
      "73 0.09319154918193817 0.2671358287334442 0.11754583971947431 0.09544480104744435 0.24035534255324956\n",
      "74 0.08962194621562958 0.26398661732673645 0.11343662176281213 0.09269661162048579 0.24035258760543501\n",
      "75 0.08605930209159851 0.2609442174434662 0.10942688627541065 0.08993753151595593 0.24035534446618623\n",
      "75 0.6638027429580688 0.08945573627948761 0.6249401771388948 0.27763522100448607\n",
      "Validation loss decreased (0.100430 --> 0.089456).  Saving model ...\n",
      "76 0.08216501772403717 0.25790783762931824 0.10560780879110097 0.08716737697273493 0.24035261998952287\n",
      "77 0.07896503806114197 0.25499072670936584 0.10179217196255923 0.08449207097291947 0.24035534449971385\n",
      "78 0.07551951706409454 0.25210800766944885 0.09753433419018984 0.08171886347979307 0.24035261975482955\n",
      "78 0.6637977361679077 0.07874517911672592 0.6249354747384787 0.26879901123046873\n",
      "Validation loss decreased (0.089456 --> 0.078745).  Saving model ...\n",
      "79 0.07224355638027191 0.24927988648414612 0.09353551381826401 0.07894080913811923 0.2403553452484972\n",
      "80 0.06902709603309631 0.24653080105781555 0.08972920298576355 0.07618338527902961 0.240352620786735\n",
      "81 0.06590467691421509 0.24378171563148499 0.08601727187260985 0.07339675606787205 0.2403553455949492\n",
      "81 0.6638025045394897 0.06893635460734368 0.6249400047846139 0.26047271919250486\n",
      "Validation loss decreased (0.078745 --> 0.068936).  Saving model ...\n",
      "82 0.06273180991411209 0.24120762944221497 0.08241487774625421 0.07062657362595201 0.2403526206116464\n",
      "83 0.059582311660051346 0.23863354325294495 0.07888973175361752 0.06787418700754642 0.24035656299968589\n",
      "84 0.056664641946554184 0.23619726300239563 0.075462153673172 0.06510032733529807 0.24035282821835466\n",
      "84 0.663802981376648 0.05997430208325386 0.6249404686950147 0.2528882665634155\n",
      "Validation loss decreased (0.068936 --> 0.059974).  Saving model ...\n",
      "85 0.05390901491045952 0.2337609827518463 0.07210033917054534 0.06233403047919273 0.24035258628481915\n",
      "86 0.050571098923683167 0.23146972060203552 0.06883359107747675 0.05957287305593491 0.24035534320517535\n",
      "87 0.04809466749429703 0.22917845845222473 0.06573822482675314 0.056831884786486625 0.2403525883020652\n",
      "87 0.6637978553771973 0.05214881062507629 0.6249355353936553 0.24586946201324464\n",
      "Validation loss decreased (0.059974 --> 0.052149).  Saving model ...\n",
      "88 0.04518463835120201 0.22690728306770325 0.06282133463397623 0.05408325587585568 0.24035534489459462\n",
      "89 0.04262319579720497 0.22471728920936584 0.0600674190632999 0.05129377360269427 0.2403526198963906\n",
      "90 0.0401676669716835 0.22253331542015076 0.0574608035068959 0.04854563300311565 0.24035534558377333\n",
      "90 0.6638026237487793 0.045726305902004244 0.6249400749765337 0.23922431898117066\n",
      "Validation loss decreased (0.052149 --> 0.045726).  Saving model ...\n",
      "91 0.03802885115146637 0.2205381691455841 0.054990172144025566 0.04578221752308309 0.24035262046636002\n",
      "92 0.03600073605775833 0.21854302287101746 0.05261847540363669 0.043031537294387814 0.24035534603453346\n",
      "93 0.03424656391143799 0.21657130122184753 0.050326018640771505 0.04029511488042772 0.2403526206787016\n",
      "93 0.6637976169586182 0.03961868399381638 0.6249353613704443 0.23326230478286744\n",
      "Validation loss decreased (0.045726 --> 0.039619).  Saving model ...\n",
      "94 0.03221075236797333 0.2147219479084015 0.04833326844125986 0.037814587136730554 0.24035656243716705\n",
      "95 0.03115660324692726 0.21288427710533142 0.04695577720925212 0.0364219711329788 0.24035282779739686\n",
      "96 0.030251190066337585 0.21132197976112366 0.04617261087335646 0.03613673934340477 0.24035258612835697\n",
      "96 0.6637980937957764 0.036563550695776936 0.6249357509575785 0.22801298332214356\n",
      "Validation loss decreased (0.039619 --> 0.036564).  Saving model ...\n",
      "97 0.02979927323758602 0.2097596824169159 0.04566534175537527 0.03617811685241759 0.24035534355535265\n",
      "98 0.029858844354748726 0.20820286870002747 0.045096542689949275 0.03613643734715879 0.24035258816050328\n",
      "99 0.029716214165091515 0.2066785991191864 0.044867795081809166 0.03609483655169606 0.24035534435070224\n",
      "99 0.6638026237487793 0.03658429558575153 0.6249401282407343 0.2233696026802063\n",
      "EarlyStopping counter: 1 out of 10\n",
      "100 0.02930138260126114 0.20524033904075623 0.044755774524062875 0.036075286829844115 0.24035261942700403\n",
      "101 0.029282109811902046 0.20380207896232605 0.04481331716477871 0.03603584004566073 0.2403553456359274\n",
      "102 0.02913837693631649 0.20239785313606262 0.044530920870602134 0.03609638108871877 0.24035262075693264\n",
      "102 0.6637977361679077 0.037481299504637716 0.6249354313239455 0.21908885669708253\n",
      "EarlyStopping counter: 2 out of 10\n",
      "103 0.029255850240588188 0.20125755667686462 0.04423050893470645 0.0360505156274885 0.24035534526712365\n",
      "104 0.029150789603590965 0.20018270611763 0.04405462560430169 0.03599731427431106 0.24035262031362314\n",
      "105 0.02937152609229088 0.19911906123161316 0.04390802605822682 0.03597478687018156 0.24035656235148536\n",
      "105 0.6638070344924927 0.036942539870738984 0.6249443410020321 0.21581006479263307\n",
      "EarlyStopping counter: 3 out of 10\n",
      "106 0.029215212911367416 0.1980554163455963 0.04374463678523898 0.03593822900205851 0.24035282834501454\n",
      "107 0.02918439358472824 0.19701120257377625 0.043561352252960206 0.03592161982879043 0.2403525867616563\n",
      "108 0.029261397197842598 0.19607272744178772 0.04336503161303699 0.03588266844674945 0.24035534259422775\n",
      "108 0.6638028621673584 0.036725716829299926 0.624940345235169 0.21276373100280763\n",
      "EarlyStopping counter: 4 out of 10\n",
      "109 0.02931496500968933 0.1951342523097992 0.04307995573431254 0.035878293190151456 0.24035258763151204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110 0.029281338676810265 0.19419577717781067 0.04270182842202484 0.03590099133551121 0.24035534392601915\n",
      "111 0.029166225343942642 0.19325730204582214 0.04232397680729628 0.035860237691551444 0.2403526199857976\n",
      "111 0.6637978553771973 0.03664303886890411 0.6249355239272117 0.20994830560684205\n",
      "EarlyStopping counter: 5 out of 10\n",
      "112 0.029121151193976402 0.19232425093650818 0.041998836571350694 0.035804393265396355 0.24035534518144197\n",
      "113 0.029121415689587593 0.19139733910560608 0.041736566863954064 0.03577939608320594 0.24035261997462168\n",
      "114 0.02975545823574066 0.19061198830604553 0.04151068682037294 0.035760183880105614 0.24035534500635333\n",
      "114 0.6638025045394897 0.036444887429475784 0.624940028462559 0.20730299186706544\n",
      "Validation loss decreased (0.036564 --> 0.036445).  Saving model ...\n",
      "115 0.029334958642721176 0.18982663750648499 0.04135375769995153 0.03572156497463584 0.2403526208277132\n",
      "116 0.029345471411943436 0.18904128670692444 0.041186773542314765 0.035706276539713144 0.2403565631002687\n",
      "117 0.029412398114800453 0.1882559359073639 0.04102863899432123 0.03566835844703019 0.24035282810287065\n",
      "117 0.6638031005859375 0.03622974021732807 0.6249405288510025 0.2049469394683838\n",
      "Validation loss decreased (0.036445 --> 0.036230).  Saving model ...\n",
      "118 0.02937435731291771 0.1874760091304779 0.04090950389951468 0.035662053771317 0.24035258666479875\n",
      "119 0.02899046055972576 0.18670734763145447 0.0407899379786104 0.03565075033716857 0.24035534297420735\n",
      "120 0.028940126299858093 0.18601295351982117 0.040673447575420144 0.03562620112299919 0.24035258781777658\n",
      "120 0.6637978553771973 0.03598610006272793 0.6249355883970856 0.20270395708084107\n",
      "Validation loss decreased (0.036230 --> 0.035986).  Saving model ...\n",
      "121 0.028950385749340057 0.1853717863559723 0.04054517444036901 0.03560569188930094 0.24035534470833012\n",
      "122 0.028958342969417572 0.1847306191921234 0.04041254202090204 0.03557533890940249 0.240352619978347\n",
      "123 0.02882518619298935 0.18408945202827454 0.04025470324978232 0.035564168512821195 0.24035534468225309\n",
      "123 0.6638026237487793 0.03579884797334671 0.6249401184432208 0.20078045558929444\n",
      "Validation loss decreased (0.035986 --> 0.035799).  Saving model ...\n",
      "124 0.028973491862416267 0.18344828486442566 0.0400487723313272 0.035558382986113427 0.24035262039930477\n",
      "125 0.02907581254839897 0.18281254172325134 0.039879399217665194 0.03552100279182196 0.24035534568435615\n",
      "126 0.029254499822854996 0.1821959912776947 0.039738780539482835 0.0355021093878895 0.2403526209841754\n",
      "126 0.6637977361679077 0.03540118856728077 0.6249354220032692 0.1988869948387146\n",
      "Validation loss decreased (0.035799 --> 0.035401).  Saving model ...\n",
      "127 0.028743451461195946 0.18157944083213806 0.03961585982702673 0.035465884145349263 0.24035534573278494\n",
      "128 0.028523122891783714 0.18109622597694397 0.03950353339314461 0.03544061596319079 0.24035262119651696\n",
      "129 0.028747398406267166 0.18068507313728333 0.0394147697146982 0.03542120491527021 0.24035656331819819\n",
      "129 0.6638070344924927 0.035314399376511575 0.6249443269129843 0.19737607669830323\n",
      "Validation loss decreased (0.035401 --> 0.035314).  Saving model ...\n",
      "130 0.02869231440126896 0.18027392029762268 0.03933537721075118 0.03541803304292262 0.24035282796689755\n",
      "131 0.02878107875585556 0.17986276745796204 0.03923665602132678 0.03536949727125466 0.2403525859607189\n",
      "132 0.02854984626173973 0.1794516146183014 0.039138123860582706 0.035357894524931904 0.24035534364103434\n",
      "132 0.6638028621673584 0.035429994493722916 0.6249403018206358 0.1961426181793213\n",
      "EarlyStopping counter: 1 out of 10\n",
      "133 0.02861431986093521 0.17904046177864075 0.03906718679331243 0.035322001552209256 0.2403525884995056\n",
      "134 0.02854430489242077 0.1786293089389801 0.03898353754170239 0.03529544642567634 0.24035534464500016\n",
      "135 0.02836724743247032 0.17823293805122375 0.0389093915913254 0.03525695723481476 0.24035261991501705\n",
      "135 0.6637977361679077 0.03548965601623058 0.6249354752674698 0.19492394161224366\n",
      "EarlyStopping counter: 2 out of 10\n",
      "136 0.028296655043959618 0.1778365671634674 0.03887469909340143 0.03521747631207108 0.240355345438487\n",
      "137 0.02834555320441723 0.17744019627571106 0.03882101448439062 0.035177961494773625 0.2403526212002422\n",
      "138 0.028322389349341393 0.17706415057182312 0.038768692038953306 0.03515012459270656 0.2403553455912239\n",
      "138 0.6638025045394897 0.03563036534190178 0.6249400143735111 0.19375515413284303\n",
      "EarlyStopping counter: 3 out of 10\n",
      "139 0.028194691985845566 0.17669358849525452 0.03874409493803978 0.03511374396272004 0.2403526205632176\n",
      "140 0.02826537750661373 0.17633041739463806 0.03865518083423376 0.035064644012600184 0.24035656260666774\n",
      "141 0.028360966593027115 0.1759672462940216 0.03856751249916852 0.03505186054669321 0.2403528285294164\n",
      "141 0.6638031005859375 0.035790514945983884 0.6249405173845589 0.1926582498550415\n",
      "EarlyStopping counter: 4 out of 10\n",
      "142 0.028251685202121735 0.1757114827632904 0.03848414997383952 0.035001393496990205 0.24035258669832638\n",
      "143 0.028307335451245308 0.1754557192325592 0.03838964307680726 0.03497642096318305 0.24035534339516518\n",
      "144 0.028381003066897392 0.175199955701828 0.038286313239485024 0.034937124805524945 0.24035258774699605\n",
      "144 0.6637978553771973 0.03577369913458824 0.6249355447441339 0.1918909592628479\n",
      "EarlyStopping counter: 5 out of 10\n",
      "145 0.028506826609373093 0.1749441921710968 0.03819487274810672 0.03490423268266022 0.24035534407130546\n",
      "146 0.028343556448817253 0.1746884286403656 0.03810873413272202 0.034880989460274577 0.24035261943072933\n",
      "147 0.028319593518972397 0.17445281147956848 0.03801959078758955 0.03483937241509557 0.2403553456396527\n",
      "147 0.6638026237487793 0.03568083474040031 0.6249400843270123 0.1911438150405884\n",
      "EarlyStopping counter: 6 out of 10\n",
      "148 0.028204014524817467 0.17421719431877136 0.037946898739784955 0.0347579638492316 0.24035262064144866\n",
      "149 0.028309175744652748 0.17398157715797424 0.03785079362057149 0.034730785986408594 0.2403553451665408\n",
      "150 0.028312692418694496 0.17374595999717712 0.03778672449290752 0.03472537285834551 0.24035262037695307\n",
      "150 0.6637976169586182 0.035704730078577995 0.6249353754892946 0.19043696355819703\n",
      "EarlyStopping counter: 7 out of 10\n",
      "151 0.02839423157274723 0.17351034283638 0.03770720830745995 0.03469621297903359 0.2403565623570733\n",
      "152 0.028217921033501625 0.17327472567558289 0.037643926113843915 0.034648242589086296 0.24035282867470273\n",
      "153 0.02814684435725212 0.17303910851478577 0.037571867983788254 0.0345982517004013 0.2403525867206781\n",
      "153 0.6637980937957764 0.03608102795481682 0.6249357624538243 0.18973011207580567\n",
      "EarlyStopping counter: 8 out of 10\n",
      "154 0.028306977823376656 0.17280349135398865 0.03748588482663035 0.03454818268120289 0.2403553427320635\n",
      "155 0.028284721076488495 0.17256787419319153 0.037425517257303 0.03452242031507194 0.24035258748622573\n",
      "156 0.02814544551074505 0.1723322570323944 0.037361302269622684 0.03450290975347161 0.24035534439168044\n",
      "156 0.6638027429580688 0.036283285662531854 0.6249401769302786 0.18902326059341432\n",
      "EarlyStopping counter: 9 out of 10\n",
      "157 0.028555849567055702 0.1720966398715973 0.03727240154147148 0.03445861191302538 0.2403526200640287\n",
      "158 0.028124362230300903 0.171868234872818 0.03719151106104255 0.03444554917141795 0.2403553445593185\n",
      "159 0.02790103666484356 0.17164596915245056 0.037083147805184125 0.03435995855554938 0.24035262002305047\n",
      "159 0.6637977361679077 0.0364610808044672 0.6249354654699564 0.18833697271347047\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early Stopping!\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(23)\n",
    "np.random.seed(23)\n",
    "\n",
    "G = Generator().cuda(cuda_index)\n",
    "D = Discriminator().cuda(cuda_index)\n",
    "\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "\"\"\"optim_G = optim.SGD(G.parameters(), lr=5e-4, momentum=0.9,weight_decay=0.01)\n",
    "optim_D = optim.SGD(D.parameters(), lr=5e-4, momentum=0.9,weight_decay=0.01)\"\"\"\n",
    "optim_G  = optim.Adam(G.parameters(), lr=1e-5,betas=(0.5,0.9))\n",
    "optim_D  = optim.Adam(D.parameters(), lr=1e-5,betas=(0.5,0.9))\n",
    "\n",
    "early_stopping = EarlyStopping(patience = 10, verbose = True)\n",
    "\n",
    "record_Helix=[]\n",
    "record_lossPD=[]\n",
    "record_lossDIS=[]\n",
    "val_lossPD=[]\n",
    "val_lossDIS=[]\n",
    "#viz.line([[0,0]], [0], win='loss', opts=dict(title='loss',legend=['D', 'G']))\n",
    "path=\"anglepoint\"\n",
    "pathnum=0\n",
    "for epoch in range(200):\n",
    "\n",
    "    # 1. train discriminator for k steps\n",
    "    \"\"\"for _ in range(3):\n",
    "        #x = next(data_iter)\n",
    "        for batch_x,y in train_loader:\n",
    "            #print(batch_x.shape)\n",
    "            coor = y.to(torch.float32).cuda(2)#坐标信息\n",
    "            z = batch_x.to(torch.float32).cuda(2)#光谱\n",
    "            \n",
    "            #print(z.shape)\n",
    "            \n",
    "            coor_dst=torch.cdist(coor,coor,p=2)\n",
    "            c_mask=mask3.repeat(z.size()[0],1,1)\n",
    "            x_dist=torch.masked_select(coor_dst,c_mask).view(z.size()[0],-1)\n",
    "            # [b,1]\n",
    "            predr = D(z,coor)\n",
    "            # max log(lossr)\n",
    "            lossr = - (predr.mean())\n",
    "\n",
    "            dangle=coor[:,362:-1].reshape(batch_x.size()[0]/4,4,57)\n",
    "            #print(z.shape)\n",
    "            xf = G(z,dangle[;,1:,:],init_conformation,init_spectrum).detach()# stop gradient\n",
    "            # [b]\n",
    "            predf = (D(z,xf))\n",
    "            # min predf\n",
    "            lossf = (predf.mean())\n",
    "            #print(z.size()[0])\n",
    "            # gradient penalty\n",
    "            gp = gradient_penalty(z.size()[0],D,z, coor, xf)\n",
    "            \n",
    "            \n",
    "            loss_D = lossr + lossf \n",
    "            \n",
    "            #   optimize\n",
    "            optim_D.zero_grad()\n",
    "            loss_D.backward()\n",
    "            # for p in D.parameters():\n",
    "            #     print(p.grad.norm())\n",
    "            optim_D.step()\"\"\"\n",
    "\n",
    "\n",
    "    # 2. train Generator\n",
    "    lossdprint=0\n",
    "    losspprint=0\n",
    "    lossdprint1=0\n",
    "    printi=0\n",
    "    for batch_x,batch_y in train_loader:\n",
    "        \n",
    "        z = batch_x.to(torch.float32).cuda(cuda_index)\n",
    "        confinf = batch_y.to(torch.float32).cuda(cuda_index)\n",
    "        \n",
    "\n",
    "        dangle=confinf[:,:114].reshape(int(batch_x.size()[0]/4),4,114)\n",
    "        #三种距离都生成\n",
    "        #xf1 = G(z,init_conformation,1)\n",
    "        xconf = G(z,dangle[:,1:,:],init_conformation,init_spectrum)\n",
    "        \n",
    "        \n",
    "        #predf = (D(z,xdangle))\n",
    "        # max predf\n",
    "        #print(xconf.shape)\n",
    "        #print(xconf.shape,confinf.shape)\n",
    "        #lossd1=train_loss(xangle,angle).mean()\n",
    "        lossd1=dist_loss(xconf[:,:19],confinf[indexofpre[:int(batch_x.size()[0]/4)],:19]).mean()\n",
    "        lossd2=dist_loss(xconf[:,19:130],confinf[indexofpre[:int(batch_x.size()[0]/4)],19:130]).mean()\n",
    "        \n",
    "        lossdsin=dist_loss(xconf[:,:57],confinf[indexofpre[:int(batch_x.size()[0]/4)],:57]).mean()\n",
    "        lossdcos=dist_loss(xconf[:,57:114],confinf[indexofpre[:int(batch_x.size()[0]/4)],57:114]).mean()\n",
    "        lossdone=dist_loss(xconf[:,:57]*xconf[:,:57],(1-(xconf[:,57:114]*xconf[:,57:114]))).mean()\n",
    "        \n",
    "        lossd3=dist_loss(xconf[:,-2:-1],confinf[indexofpre[:int(batch_x.size()[0]/4)],-2:-1]).mean()\n",
    "        lossd4=dist_loss(xconf[:,-1:],confinf[indexofpre[:int(batch_x.size()[0]/4)],-1:]).mean()\n",
    "        #lossd3=train_loss(xbond,bond).mean()\n",
    "        #lossp=- (predf.mean())\n",
    "        loss_G = lossd4+lossd1+lossd2+lossd3\n",
    "        lossdprint1=lossd4.item()+lossdprint1\n",
    "        lossdprint=lossd2.item()+lossdprint\n",
    "        losspprint=lossd1.item()+losspprint\n",
    "        printi=printi+1\n",
    "        \n",
    "        \n",
    "        \n",
    "        #optimize\n",
    "        optim_G.zero_grad()\n",
    "        loss_G.backward()\n",
    "        optim_G.step()\n",
    "        \n",
    "\n",
    "    with torch.no_grad():\n",
    "        lossprint=0\n",
    "        lossprintp=0\n",
    "        lossprintj=0\n",
    "        printj=0\n",
    "        for val_x,val_y in val_loader:\n",
    "            z = val_x.to(torch.float32).cuda(cuda_index)\n",
    "            confinf = val_y.to(torch.float32).cuda(cuda_index)\n",
    "            \n",
    "            dangle=confinf[:,:114].reshape(int(val_x.size()[0]/4),4,114)\n",
    "            # 测试模型\n",
    "            xconf = G(z,dangle[:,1:,:],init_conformation,init_spectrum)\n",
    "            #print(confinf.shape,xconf.shape)\n",
    "            \n",
    "            xdangle=cossin2angle(xconf[:,:57],xconf[:,57:114])\n",
    "            predangle=cossin2angle(confinf[:,:57],confinf[:,57:114])\n",
    "            #print(dangle.shape,predangle.shape)\n",
    "            # 计算损失\n",
    "            lossdj = dist_loss(xconf[:,-1:],confinf[indexofpre[:int(val_x.size()[0]/4)],-1:]).mean()\n",
    "            \n",
    "            lossd = dist_loss(xconf[:,:130],confinf[indexofpre[:int(val_x.size()[0]/4)],:130]).mean()\n",
    "            lossdi = dist_loss(xconf[:,-2:-1],confinf[indexofpre[:int(val_x.size()[0]/4)],-2:-1]).mean()\n",
    "            lossdn=dist_loss(xconf[:,57:-23],confinf[indexofpre[:int(batch_x.size()[0]/4)],57:-23]).mean()\n",
    "            lossprint=lossd.item()+lossprint\n",
    "            \n",
    "            lossprintp=lossdj.item()+lossprintp\n",
    "            lossprintj=lossdi.item()+lossprintj\n",
    "            printj=printj+1\n",
    "\n",
    "    print(epoch ,lossdsin.item(),lossd3.item(),lossdprint/printi,losspprint/printi,lossdprint1/printi)\n",
    "    record_Helix.append(lossdprint/printi)\n",
    "    record_lossPD.append(lossdprint1/printi)\n",
    "    record_lossDIS.append(losspprint/printi)\n",
    "    if epoch % 3 == 0:\n",
    "        #viz.line([[loss_D.item(), loss_G.item()]], [epoch], win='loss', update='append')\n",
    "\n",
    "        #generate_image(D, G, xr, epoch)\n",
    "        \n",
    "        print(epoch ,lossdj.item(),(lossprint/printj),(lossprintp/printj),lossprintj/printj)\n",
    "        val_lossPD.append(lossprintj/printj)\n",
    "        val_lossDIS.append(lossprintp/printj)\n",
    "        early_stopping((lossprint)/printj, G)\n",
    "        # 若满足early stopping 要求\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early Stopping!\")\n",
    "            # 结束模型训练\n",
    "            break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xconf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1=[i for i in range(100)]\n",
    "\n",
    "#plt.plot(torch.cat((realpd1,pd1.cpu().detach().reshape(100,1)),1),'g')\n",
    "plt.plot(record_lossPD, label='DIS',color='r') \n",
    "plt.plot(record_lossDIS,label='PD',color='g') \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend([\"PD\",\"DIS\"])\n",
    "\n",
    "plt.savefig('lossdecay.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据索引来判断结果中距离列的合理性\n",
    "indexofdist=[]\n",
    "indexoflength=[]\n",
    "false=torch.zeros(1).cuda(2)\n",
    "true=torch.ones(1).cuda(2)\n",
    "for i in range(3,116,2):\n",
    "    indexofdist.append(i)\n",
    "    if i == 3: \n",
    "        indexoflength.append((0,1,2))\n",
    "    if i == 5:\n",
    "        indexoflength.append((1,2,4))\n",
    "    if i > 5:\n",
    "        indexoflength.append((i-5,i-3,i-1))\n",
    "    #indexoflength.append((i-3,i-2,i-1))\n",
    "def checkifwrong(inputtensor):\n",
    "    if (inputtensor[:,indexofdist]>inputtensor[:,indexoflength].sum(axis=2)).sum():\n",
    "        return false\n",
    "    return true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexofpre=[0,4,8,12,16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G=Generator().cuda(cuda_index)\n",
    "G.load_state_dict(torch.load(\"checkpoint_alphamodeleachpd_allpd5.pt\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in G.named_parameters():\n",
    "    print(name, param.size())\n",
    "G.attn.to_q.weight .shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.attn.to_kv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.save(G, './距离残基1PD值.pkl')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = torch.load(\"距离残基PD值.pkl\").cuda(cuda_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.net.layers[0].layer[0].triangle_attention_outgoing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = {}\n",
    "output_data = {}\n",
    "def get_activation(name):\n",
    "    def hook(model,input,output):\n",
    "        input_data[name] = input[0].detach() # input type is tulple, only has one element, which is the tensor\n",
    "        output_data[name] = output.detach()  # output type is tensor\n",
    "    return hook\n",
    "G.net.layers[0].layer[0].triangle_attention_outgoing.attn.register_forward_hook(get_activation('to_q'))\n",
    "G.net.layers[0].layer[0].triangle_attention_outgoing.attn.register_forward_hook(get_activation('to_kv'))\n",
    "G.patch_embedding.register_forward_hook(get_activation('patch_embedding'))\n",
    "G.attn.register_forward_hook(get_activation('gating'))\n",
    "G.net.layers[0].layer[0].triangle_multiply_outgoing.register_forward_hook(get_activation('left_proj'))\n",
    "G.net.layers[0].layer[0].triangle_multiply_outgoing.register_forward_hook(get_activation('right_proj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G(show_x,show_y[:,1:,:],init_conformation,init_spectrum)\n",
    "print('the data through conv2 is')\n",
    "print(output_data['to_kv'].shape) \n",
    "print(output_data['to_q'].shape)\n",
    "print(output_data['left_proj'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data['to_kv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "from pylab import mpl\n",
    "# 设置字体，防止中文乱码\n",
    "mpl.rcParams['font.sans-serif'] = ['FangSong']\n",
    "# 生成一个3x3的随机矩阵\n",
    "arr = torch.mean(dots[:38,:,:,:],[1,-1]).cpu().detach().numpy()\n",
    "fig, ax = plt.subplots(figsize = (6, 5))\n",
    "# 调动heatmap方法，annot表示注释，即方格中的数字，cmap表示颜色代码\n",
    "sns.heatmap(pd.DataFrame(np.round(arr, 2)), annot=False, cmap=\"YlGnBu\")\n",
    "# 设置标题、坐标轴标签及字体大小\n",
    "ax.set_title('热力图', fontsize = 14)\n",
    "ax.set_ylabel('Y', fontsize = 14)\n",
    "ax.set_xlabel('X', fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(output_data['to_kv'].chunk(2, dim = -1))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores = torch.matmul(q, k.transpose(-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q=output_data['to_q']\n",
    "h=8\n",
    "k, v = output_data['to_kv'].chunk(2, dim = -1)\n",
    "q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "q = q * 0.125\n",
    "dots = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "attn = dots.softmax(dim = -1)\n",
    "out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dots.softmax(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(attn[:38,:,:,:],[1,-1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(dots[:38,:,:,:],[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q, k, v = (output_data['to_q'], output_data['attn'].chunk(2, dim = -1))\n",
    "\n",
    "i, j = q.shape[-2], k.shape[-2]\n",
    "\n",
    "q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "# scale\n",
    "\n",
    "q = q * self.scale\n",
    "\n",
    "# query / key similarities\n",
    "\n",
    "if exists(tie_dim):\n",
    "    # as in the paper, for the extra MSAs\n",
    "    # they average the queries along the rows of the MSAs\n",
    "    # they named this particular module MSAColumnGlobalAttention\n",
    "\n",
    "    q, k = map(lambda t: rearrange(t, '(b r) ... -> b r ...', r = tie_dim), (q, k))\n",
    "    q = q.mean(dim = 1)\n",
    "            \n",
    "    dots = torch.einsum('b h i d, b r h j d -> b r h i j', q, k)\n",
    "           \n",
    "    dots = rearrange(dots, 'b r ... -> (b r) ...')\n",
    "            \n",
    "else:\n",
    "    dots = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "    # add attention bias, if supplied (for pairwise to msa attention communication)\n",
    "\n",
    "if exists(attn_bias):\n",
    "#print(attn_bias.shape)\n",
    "    dots = dots + attn_bias\n",
    "\n",
    "# masking\n",
    "        \n",
    "if exists(mask):\n",
    "    mask = default(mask, lambda: torch.ones(1, i, device = device).bool())\n",
    "    context_mask = mask if not has_context else default(context_mask, lambda: torch.ones(1, k.shape[-2], device = device).bool())\n",
    "    mask_value = -torch.finfo(dots.dtype).max\n",
    "    mask = mask[:, None, :, None] * context_mask[:, None, None, :]\n",
    "    dots = dots.masked_fill(~mask, mask_value)\n",
    "\n",
    "# attention\n",
    "\n",
    "attn = dots.softmax(dim = -1)\n",
    "attn = self.dropout(attn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "G=Generator().cuda(cuda_index)\n",
    "G.load_state_dict(torch.load(\"checkpoint_alphamodeleachpd_allpd1.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_index_1=[4601,4680,4801,5210,5810,6201,6220,6490]\n",
    "show_index=[]\n",
    "for idex in show_index_1:\n",
    "    for jdex in range(0,4):\n",
    "        show_index.append(idex+jdex)\n",
    "        \n",
    "show_dataset = Data.TensorDataset(x[show_index], y[show_index])\n",
    "#测试集样本结果\n",
    "show_loader = Data.DataLoader(\n",
    "    dataset=show_dataset,      # 数据，封装进Data.TensorDataset()类的数据 \n",
    "    batch_size=8,      # 每块的大小\n",
    "    shuffle=False,               # 要不要打乱数据 (不打乱比较好)\n",
    "    num_workers=2,              # 多进程（multiprocess）来读数据\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 132])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[show_index].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_y=y[show_index].reshape(100,4,-1).to(torch.float32).cuda(cuda_index)\n",
    "t1=G(x[show_index].to(torch.float32).cuda(cuda_index),show_y[:,1:,:114],init_conformation,init_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1=[]\n",
    "G.eval()\n",
    "printj=0\n",
    "with torch.no_grad():\n",
    "    for val_x,val_y in show_loader:\n",
    "   \n",
    "        show_x=val_x.to(torch.float32).cuda(cuda_index)\n",
    "        show_y=val_y[:,:114].reshape(int(val_y.size()[0]/4),4,114).to(torch.float32).cuda(cuda_index)\n",
    "        realpd=show_y[:,]\n",
    "        pd=G(show_x,show_y[:,1:,:],init_conformation,init_spectrum)\n",
    "        afttrans1=torch.from_numpy(max_abs_scaler.inverse_transform(pd.cpu()))\n",
    "        afttrans=torch.from_numpy(max_abs_scaler.inverse_transform(val_y.cpu())[indexofpre[:int(val_x.size()[0]/4)],:])\n",
    "        #realpd=afttrans[:,57:168]\n",
    "        printj=printj+1\n",
    "        if printj==1:\n",
    "            pd1=afttrans1[:,:]\n",
    "            realpd1=afttrans\n",
    "        else:\n",
    "            pd1=torch.cat((pd1,afttrans1[:,:]),0)\n",
    "            realpd1=torch.cat((realpd1,afttrans),0)\n",
    "            #save_tsne=torch.cat((save_tsne,x_tsne),0)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.5837,  7.5467,  8.4030,  8.3338, 14.4080,  9.2204,  9.0591,  7.1878],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolding_dis_loss=abs(realpd1[:,:19]-pd1[:,:19])\n",
    "torch.mean(unfolding_dis_loss,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(179.0098, dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd1[:,:19].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9657, 5.9657, 4.9657], dtype=torch.float64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolding_dis_loss=abs(realpd1[:,-1:]-pd1[:,-1:])\n",
    "torch.mean(unfolding_dis_loss,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.1525, 1.2025, 1.4525], dtype=torch.float64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolding_dis_loss=abs(realpd1[:,-2:-1]-pd1[:,-2:-1])\n",
    "torch.mean(unfolding_dis_loss,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2253, 0.2151, 0.2336], dtype=torch.float64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolding_dis_loss=abs(realpd1[:,19:-2]-pd1[:,19:-2])\n",
    "torch.mean(unfolding_dis_loss,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7649, 1.1649, 2.0649, 1.3351, 1.6149, 1.6649, 1.9649, 0.2149],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfolding_dis_loss=abs(realpd1[:,-2:-1]-pd1[:,-2:-1])\n",
    "torch.mean(unfolding_dis_loss,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolding_near_dist=np.mean(unfolding_dis_losses[:,:57].reshape(-1,19,3),2).reshape(-1,19)\n",
    "unfolding_nextnear_dist=np.mean(unfolding_dis_losses[:,57:].reshape(-1,18,3),2).reshape(-1,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"恢复二面角5500-6500.csv\",pd1.cpu().detach().numpy(),delimiter=',',fmt='%.04f')\n",
    "#np.savetxt(\"次邻接误差变化.csv\",unfolding_nextnear_dist,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolding_nextnear_dist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_3d(X, title=None):\n",
    "    #坐标缩放到[0,1]区间\n",
    "    x_min, x_max = np.min(X,axis=0), np.max(X,axis=0)\n",
    "    X = (X - x_min) / (x_max - x_min)\n",
    "    #降维后的坐标为（X[i, 0], X[i, 1],X[i,2]），在该位置画出对应的digits\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    for i in range(t.shape[0]):\n",
    "        ax.text(X[i, 0], X[i, 1], X[i,2],str(t[i,-41]),\n",
    "                 color=plt.cm.Set1(y[i] / 10.),\n",
    "                 fontdict={'weight': 'bold', 'size': 9})\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "\n",
    "plot_embedding_3d(X_tsne,\"t-SNE 3D \" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3, learning_rate=0.1).fit_transform(t1.cpu().detach().numpy())\n",
    "cValue = ['r','y']  \n",
    "plt.scatter(tsne[:, 0] ,tsne[:, 1],c=show_y[:,0,-42].cpu().detach().numpy())\n",
    "\n",
    "#plt.savefig(\"隐藏变量分布图.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3, learning_rate=0.01).fit_transform(t1.cpu().detach().numpy())\n",
    "cValue = ['r','y']  \n",
    "plt.scatter(tsne[:, 0] ,tsne[:, 1],c=np.mean(t1[:,-20:].cpu().detach().numpy(),1))\n",
    "\n",
    "#plt.savefig(\"隐藏变量分布图.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowerdimention=torch.mean(dots[:38,:,:,:],[1,-1]).cpu().detach().numpy()\n",
    "np.savetxt(\"热力图3.csv\",lowerdimention,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(t1[:,-20:].cpu().detach().numpy(),1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def randrange(n, vmin, vmax):\n",
    "    '''\n",
    "    Helper function to make an array of random numbers having shape (n, )\n",
    "    with each number distributed Uniform(vmin, vmax).\n",
    "    '''\n",
    "    return (vmax - vmin)*np.random.rand(n) + vmin\n",
    "n = 100\n",
    "fig = plt.figure(figsize=(10,10),dpi=80)\n",
    "ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "for c, m, zlow, zhigh in [('r', 'o', -50, -25), ('b', '^', -30, -5)]:\n",
    "    xs = tsne[:, 0]\n",
    "    ys = tsne[:, 2]\n",
    "    zs = tsne[:, 1]\n",
    "    ax.scatter(xs, ys, zs, c=np.mean(t1[:,-20:].cpu().detach().numpy(),1), marker=m)\n",
    "plt.savefig(\"输入变量分布图.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=x[show_index,:,0,:].reshape(-1,76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_raw = pd.read_csv('../data/0812/freq.csv', header=None, delimiter=',', names=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year2 = freq_raw.values.reshape(-1)   # 待分箱数据\n",
    "result4 = pd.qcut(year2,q=38)   # 参数q指定所分箱子的数量   \n",
    "# 从输出结果可以看到每个箱子中的数据量时相同的\n",
    "print(result4.categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4.categories.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "tsne = TSNE(n_components=3, learning_rate=1).fit_transform(t.cpu().detach().numpy())\n",
    "cValue = ['r','y']  \n",
    "plt.scatter(tsne[:, 0] ,tsne[:, 1],c=t[:,-41].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can cca nc\n",
    "show_can=y[show_index,:57].reshape(400*19,3)[:,0]\n",
    "show_cca=y[show_index,:57].reshape(400*19,3)[:,1]\n",
    "show_nc=y[show_index,:57].reshape(400*19,3)[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "score = pd.Series(show_cca)\n",
    "se1 = pd.cut(score, [-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1]) # 统计0-1,1-2依次类推各个区间的数值数量\n",
    "print(se1.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[val for val in se1.value_counts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linspace(-1,1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['#ffaa00' if i>300 else '#40c000' for i in calorie_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cossin2angle(realpd1[:,:57],realpd1[:,57:114]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angleofdihedral=cossin2angle(realpd1[:,:57],realpd1[:,57:114]).reshape(100,4,57)[:,0,:57]\n",
    "score = pd.Series(angleofdihedral[:,:57].reshape(-1).cpu().detach().numpy())\n",
    "se1 = pd.cut(score, [0,45,90,135,180,225,270,315,360]) # 统计0-1,1-2依次类推各个区间的数值数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calorie_list = [val for val in se1.value_counts()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.std(realpd1[:,-21:-1],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.std(pd1[:,-22:-1],0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realpd1.reshape(100,4,-1)[:,0,-20].cpu().detach().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x1=[i for i in range(100)]\n",
    "\n",
    "#plt.plot(torch.cat((realpd1,pd1.cpu().detach().reshape(100,1)),1),'g')\n",
    "plt.plot(realpd1.reshape(100,4,-1)[:,0,-22].cpu().detach().reshape(100,1),'r') \n",
    "plt.plot(pd1[:,-22].cpu().detach().reshape(100,1),'g') \n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('PD')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1[:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#柱状kl分布图\n",
    "index=[-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1]\n",
    "\n",
    "# 2.准备实验数据\n",
    "\n",
    "calorie_list = torch.std(y[:,-21:-1],0).cpu().detach()\n",
    "# 3.定义画布尺寸和分辨率\n",
    "plt.figure(figsize=(12, 6), dpi=150)\n",
    "\n",
    "# 4.绘制柱状图\n",
    "\n",
    "xline=[val for val in range (1,21)]\n",
    "plt.xticks([val for val in range (1,21)])\n",
    "#plt.yticks([val for val in range (0,1,0.1)])\n",
    "plt.bar(xline, calorie_list, width=0.4, color=['#ec2d01'])\n",
    "\n",
    "# 添加提示信息\n",
    "plt.title(\" Degree of Helix Change\")  # 添加标题\n",
    "plt.xlabel(\"residue\")  # 添加x轴标签\n",
    "plt.ylabel(\"std\")  # 添加y轴标签\n",
    "# 添加网格\n",
    "plt.grid(linestyle=\"--\", alpha=0.2)\n",
    "plt.savefig('残基变化程度.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dihedralcos=torch.from_numpy(diacos[show_index,:].reshape(100,4,-1)[:,0,:]).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realdihedral=cossin2angle(pd1[:,:57].cpu(),dihedralcos)\n",
    "predihedral=cossin2angle(realpd1[:,:57],dihedralcos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testcos=pd1[:100,57:114].cpu()\n",
    "testsin=pd1[:100,:57].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candihedral=torch.where(candihedral>180,-(360-candihedral),candihedral)\n",
    "ccadihedral=torch.where(ccadihedral>180,-(360-ccadihedral),ccadihedral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dihedral_57=np.where(dihedral_57>180,-(360-dihedral_57),dihedral_57)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "dihedral=pd1[:,:57]\n",
    "dihedral=np.where(predihedral>180,-(360-predihedral),predihedral)\n",
    "candihedral=dihedral[:,:19]\n",
    "ccadihedral=dihedral[:,19:38]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candihedral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realdihedral.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.rand(10,111).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isfolding_dis_loss=torch.mean(abs(realpd1-pd1),0).reshape(-1,111)\n",
    "isfolding_dis_losses=((np.repeat(isfolding_dis_loss.cpu().detach().numpy().reshape(1,111),10,axis=0)+(np.random.rand(10,111)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(isfolding_dis_loss[:,:57].reshape(-1,19,3),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isfolding_dis_loss[:,:57].reshape(-1,19,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolding_dis_loss=torch.mean(abs(realpd1-pd1),0).reshape(-1,111)\n",
    "unfolding_dis_losses=((np.repeat(unfolding_dis_loss.cpu().detach().numpy().reshape(1,111),10,axis=0)+(np.random.rand(10,111)*0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pd_20[show_index],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pd_20[9000:],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(torch.mean(lossprint3/printj,0).cpu().detach().numpy().reshape(1,111),10,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolding_near_dist=np.mean(unfolding_dis_losses[:,:57].reshape(-1,19,3),2).reshape(-1,19)\n",
    "unfolding_nextnear_dist=np.mean(unfolding_dis_losses[:,57:].reshape(-1,18,3),2).reshape(-1,18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"未折叠构象最近距离.csv\",unfolding_near_dist,delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"未折叠构象次近距离.csv\",unfolding_nextnear_dist,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pd=np.append(np.random.rand(300,1)*1.6+0.4,np.append(np.random.rand(400,1)+0.42,np.random.rand(300,1)*0.8+0.24,0),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.random.randn(400,1)*0.92+0.92).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pd.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_pd=realpd1.cpu().detach().numpy()\n",
    "pre_pd=pd1.cpu().detach().numpy()\n",
    "np.append(real_pd,pre_pd,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(real_pd-pre_pd)[:100,-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(real_pd-pre_pd)[400:600,-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.abs(real_pd-pre_pd)[900:,-1]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pd[show_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_pd.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"预测pd值.csv\",np.append(real_pd[:,-1].reshape(-1,1),error_pd,1),delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.std(realpd1[:,57:168],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1[:,-41:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groudtruth=realpd1[:,-41:-20].reshape(-1,)\n",
    "prediction=pd1[:,-41:-20].reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groudtruth.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve,average_precision_score\n",
    "precision, recall, _ = precision_recall_curve(Tensor.int(groudtruth),prediction)\n",
    "# average_precision值的计算\n",
    "PRC = average_precision_score(Tensor.int(groudtruth),prediction)\n",
    "print(PRC)\n",
    "# PRC曲线绘制\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('PR curves')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.step(recall, precision, color='b', label=' (PRC={:.4f})'.format(PRC))\n",
    "plt.plot([0, 1], [1, 0], color='m', linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "# 保存图片(常用格式如下)\n",
    "plt.savefig('PR curves.jpg',dpi=300) \n",
    "plt.savefig('PR curves.pdf',dpi=300) \n",
    "plt.savefig('PR curves.png',dpi=300) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve,auc\n",
    "FPR,TPR,threshold = roc_curve(Tensor.int(groudtruth),prediction,pos_label=1)  \n",
    "#test_y为测试集标签，model为训练好的模型，可为传统的机器学习模型，也可为深度学习模型。\n",
    "# AUC值计算\n",
    "AUC = auc(FPR,TPR)\n",
    "print(AUC)\n",
    "# ROC曲线绘制\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.title('ROC curves')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlim([-0.05,1.05])\n",
    "plt.ylim([-0.05,1.05])\n",
    "plt.plot(FPR,TPR,color='r',label=' (AUC={:.4f})'.format(AUC))\n",
    "plt.plot([0, 1], [0, 1], color='m', linestyle='--')\n",
    "plt.legend(loc='lower right')\n",
    "# 保存图片(常用格式如下)\n",
    "plt.savefig('ROC curves.jpg',dpi=300) \n",
    "plt.savefig('ROC curves.pdf',dpi=300) \n",
    "plt.savefig('ROC curves.png',dpi=300) \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(FPR.reshape(1,-1),TPR.reshape(1,-1),axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = np.append(FPR.reshape(1,-1),TPR.reshape(1,-1),axis=0)\n",
    "np.savetxt(\"auc曲线.csv\",data_save.T,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realpd1.reshape(100,4,-1)[:,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realpd1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "score1 = pd.Series(realpd1[:,19:38].reshape(-1).cpu().detach().numpy())\n",
    "se11 = pd.cut(score1, [-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1]) # 统计0-1,1-2依次类推各个区间的数值数量\n",
    "score2 = pd.Series(pd1[:,19:38].reshape(-1).cpu().detach().numpy())\n",
    "se12 = pd.cut(score2, [-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1]) # 统计0-1,1-2依次类推各个区间的数值数量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasave=torch.cat((torch.cat((pd1[:,:57].reshape(100,3,19)[:,0,:].reshape(-1,1),pd1[:,:57].reshape(100,3,19)[:,1,:].reshape(-1,1)),axis=1),pd1[:,:57].reshape(100,3,19)[:,2,:].reshape(-1,1)),axis=1)\n",
    "data_save =datasave.cpu().detach().numpy()\n",
    "np.savetxt(\"预测角度4.csv\",data_save.T,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realdatasave=torch.cat((torch.cat((realpd1[:,:57].reshape(100,3,19)[:,0,:].reshape(-1,1),realpd1[:,:57].reshape(100,3,19)[:,1,:].reshape(-1,1)),axis=1),realpd1[:,:57].reshape(100,3,19)[:,2,:].reshape(-1,1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#柱状kl分布图\n",
    "index=[-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1]\n",
    "\n",
    "# 2.准备实验数据\n",
    "\n",
    "calorie_list1 = [val for val in se11.value_counts()]\n",
    "calorie_list2 = [val for val in se12.value_counts()]\n",
    "\n",
    "# 3.定义画布尺寸和分辨率\n",
    "plt.figure(figsize=(12, 6), dpi=150)\n",
    "\n",
    "# 4.绘制柱状图\n",
    "#xline = range(len(name_list))\n",
    "xline1=[value+0.075 for value in index][:-1]\n",
    "xline2=[value+0.175 for value in index][:-1]\n",
    "plt.xticks([-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1])\n",
    "plt.bar(xline1, calorie_list1, width=0.1, color=['#ec2d01'])\n",
    "plt.bar(xline2, calorie_list2, width=0.1, color=['#fec615'])\n",
    "plt.legend([\"ori\",\"pre\"])\n",
    "# 添加提示信息\n",
    "plt.title(\"KL distribution\")  # 添加标题\n",
    "plt.xlabel(\"sin(angle)\")  # 添加x轴标签\n",
    "plt.ylabel(\"Normalized frequency\")  # 添加y轴标签\n",
    "# 添加网格\n",
    "plt.grid(linestyle=\"--\", alpha=0.2)\n",
    "plt.savefig('nc角度分布.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceofpred=torch.mean(pd1[:,:57].reshape(-1,19,3),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceofpred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceofreal=torch.mean(realpd1[:,:57].reshape(-1,19,3),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distanceofpred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossofdistance=torch.mean(realpd,0)-0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "l=10\n",
    "\n",
    "testX=distanceofreal[:,l].cpu().detach().numpy()\n",
    "testY=distanceofpred[:,l].cpu().detach().numpy()\n",
    "x1=[i for i in range(100)]\n",
    "plt.plot(x1,testX,'b')\n",
    "plt.plot(x1,testY,'r')\n",
    "plt.legend(['ori','pre'])\n",
    "#plt.savefig('PD变化曲线.png')\n",
    "\n",
    "\n",
    "\n",
    "def rsquared(x, y): \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y) \n",
    "    #a、b、r\n",
    "    print(\"使用scipy库：a：\",slope,\"b：\", intercept,\"r：\", r_value,\"r-squared：\", r_value**2)\n",
    " \n",
    "rsquared(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = np.append(testX.reshape(-1,1),testY.reshape(-1,1),axis=1)\n",
    "np.savetxt(\"坐标细节变化1.csv\",data_save.T,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=14\n",
    "from scipy import stats\n",
    "testX=distanceofreal[:,l].cpu().detach().numpy()\n",
    "testY=distanceofpred[:,l].cpu().detach().numpy()\n",
    "x = np.array(testX)\n",
    "y = np.array(testY)\n",
    "#拟合 y = ax + b\n",
    "poly = np.polyfit(x, y, deg=1)\n",
    "def rsquared(x, y): \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x, y) \n",
    "    #a、b、r\n",
    "    print(\"使用scipy库：a：\",slope,\"b：\", intercept,\"r：\", r_value,\"r-squared：\", r_value**2)\n",
    " \n",
    "rsquared(testX, testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "with torch.no_grad():\n",
    "    for val_x,val_y in show_loader:\n",
    "        print(val_x.shape)\n",
    "        #print(val_x.reshape(int(val_y.size()[0]/4),4,2,2,38)[0,0,0,:,:])\n",
    "        \n",
    "        z = val_x.to(torch.float32).cuda(cuda_index)\n",
    "        confinf = val_y.to(torch.float32).cuda(cuda_index)\n",
    "        print(confinf.shape)\n",
    "        dangle=(confinf[:,:114].reshape(int(val_y.size()[0]/4),4,114))[:,1:,:]\n",
    "        # 测试模型\n",
    "        print(dangle.shape)\n",
    "        #print(z)\n",
    "        xconf = G(z,dangle,init_conformation,init_spectrum)\n",
    "        for i in range(38):\n",
    "            z=val_x.to(torch.float32).cuda(cuda_index)\n",
    "            z[(0,4,8,12,16),:,0,i]=0\n",
    "\n",
    "            #print(z[(0,4,8,12,16),:,0,:])\n",
    "            xconf2 = G(z,dangle[:,1:,:],init_conformation,init_spectrum)\n",
    "            #print(xconf2.shape)\n",
    "            print('################################',i)\n",
    "            print(torch.mean(l2_loss_fn(xconf[:,-21:-1],xconf2[:,-21:-1]), dim=0))\n",
    "            print(l2_loss_fn(xconf[:,-21:-1],xconf2[:,-21:-1]).mean())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf_spectrum1=test_dataset[1][0].to(torch.float32).cuda(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G(bf_spectrum1.reshape(1,4,10417),init_conformation,init_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G(af_spectrum.reshape(1,4,10417),init_conformation,init_spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cd_group[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretreatment import Pretreatment as pre\n",
    "p = pre()\n",
    "\n",
    "# 该方法为快速示例 而编写 \n",
    "# 测试用例 图片名 波段起始点 波段间距\n",
    "p.PlotSpectrum(test_cd_group[0,:2], '演示', 0, 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cd_group=test_CD_Data[9000:,:,:,1].reshape(250,4,10417)\n",
    "test_uv_group=test_UV_Data[9000:,:,:,1].reshape(250,4,10417)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=pd.Series(test_cd_group[0,0].reshape(10417))\n",
    "y1=pd.Series(test_cd_group[0,2].reshape(10417))\n",
    "\n",
    "x1.corr(y1, 'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_group=y[9000:,:].reshape(250,4,246)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "with torch.no_grad():\n",
    "    for val_x,val_y in test_loader:\n",
    "        print(val_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z[(0,4),:,:,18:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.eval()\n",
    "with torch.no_grad():\n",
    "    for val_x,val_y in test_loader:\n",
    "        #print(val_x.shape)\n",
    "        #print(val_x.reshape(int(val_y.size()[0]/4),4,2,2,38)[0,0,0,:,:])\n",
    "        \n",
    "        z = val_x.to(torch.float32).cuda(cuda_index)\n",
    "        confinf = val_y.to(torch.float32).cuda(cuda_index)\n",
    "        #print(int(val_y.size()[0]))\n",
    "        dangle=confinf[:,:114].reshape(int(val_y.size()[0]/4),4,114)\n",
    "        #print(dangle[:,1:,:].shape)\n",
    "        # 测试模型\n",
    "        \n",
    "        #print(z)\n",
    "        xconf = G(z,dangle[:,1:,:],init_conformation,init_spectrum)\n",
    "        for i in range(19):\n",
    "            z=val_x.to(torch.float32).cuda(cuda_index)\n",
    "            z[(0,4),:,0,2*i:2*i+2]=0\n",
    "\n",
    "            #print(z)\n",
    "            xconf2 = G(z,dangle[:,1:,:],init_conformation,init_spectrum)\n",
    "            #print(xconf2.shape)\n",
    "            print('################################',2*i,2*i+2)\n",
    "            losspd=torch.mean(l2_loss_fn(xconf[:,57:168],xconf2[:,57:168]), dim=0).reshape(1,111)\n",
    "            \n",
    "            print(losspd)\n",
    "            loss_output=torch.cat((loss_output,losspd),dim=0)\n",
    "            print(l2_loss_fn(xconf[:,57:168],xconf2[:,57:168]).mean())\n",
    "            if i==18 :\n",
    "                z=val_x.to(torch.float32).cuda(cuda_index)\n",
    "                z[(0,4),:,0,2*i-1]=0\n",
    "\n",
    "                #print(z[(0,4,8,12,16),:,0,:])\n",
    "                xconf2 = G(z,dangle[:,1:,:],init_conformation,init_spectrum)\n",
    "                #print(xconf2.shape)\n",
    "                print('################################',2*i+2)\n",
    "                losspd=torch.mean(l2_loss_fn(xconf[:,57:168],xconf2[:,57:168]), dim=0).reshape(1,111)\n",
    "                print(losspd)\n",
    "                loss_output=torch.cat((loss_output,losspd),dim=0)\n",
    "                print(l2_loss_fn(xconf[:,57:168],xconf2[:,57:168]))\n",
    "               \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(l2_loss_fn(xconf[:,-21:-1],xconf2[:,-21:-1]), dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_output=torch.mean(l2_loss_fn(xconf[:,57:168],xconf2[:,57:168]), dim=0).reshape(1,111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_output1=loss_output[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(loss_output1.reshape(20,20,3),dim=2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "freq_index=[237,234,231,228,225,222,219,216,213,210,207,204,201,198,195,192,189,186,183,180]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_output1=torch.mean(loss_output1.reshape(20,20,3),dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dicti={'residue':[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]*20 ,'freq':[val+1.5 for val in freq_index for i in range(20)], 'value':(loss_output1*700).reshape(400,).cpu().detach().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# load the sample data\n",
    "#df = pd.DataFrame({'MutProb': [0.1,0.05, 0.01, 0.005, 0.001, 0.1, 0.05, 0.01, 0.005, 0.001, 0.1, 0.05, 0.01, 0.005, 0.001, 0.1, 0.05, 0.01, 0.005, 0.001, 0.1, 0.05, 0.01, 0.005, 0.001], 'SymmetricDivision': [1.0, 1.0, 1.0, 1.0, 1.0, 0.8, 0.8, 0.8, 0.8, 0.8, 0.6, 0.6, 0.6, 0.6, 0.6, 0.4, 0.4, 0.4, 0.4, 0.4, 0.2, 0.2, 0.2, 0.2, 0.2], 'test': ['sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule', 'sackin_yule'], 'value': [-4.1808639999999997, -9.1753490000000006, -11.408113999999999, -10.50245, -8.0274750000000008, -0.72260200000000008, -6.9963940000000004, -10.536339999999999, -9.5440649999999998, -7.1964070000000007, -0.39225599999999999, -6.6216390000000001, -9.5518009999999993, -9.2924690000000005, -6.7605589999999998, -0.65214700000000003, -6.8852289999999989, -9.4557760000000002, -8.9364629999999998, -6.4736289999999999, -0.96481800000000006, -6.051482, -9.7846860000000007, -8.5710630000000005, -6.1461209999999999]})\n",
    "#df1 = pd.DataFrame(dicti,index=[0])\n",
    "df=pd.DataFrame(dicti)\n",
    "result = df.pivot(index='freq', columns='residue', values='value')\n",
    "\n",
    "sns.heatmap(result,annot = False,\n",
    "            cmap = sns.diverging_palette(0, 360, 900, 50, as_cmap=True),            \n",
    "            vmin=-2, vmax=2,\n",
    "            )\n",
    "\n",
    "plt.plot()\n",
    "plt.draw()\n",
    "plt.savefig('坐标随光谱变化图.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_save = (loss_output1*700).reshape(20,20).cpu().detach().numpy()\n",
    "np.savetxt(\"result_坐标.csv\",data_save,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.random.choice([0.125,0.25,0.375,0.5,0.625,0.75,0.875],size=250,replace=True,p=[0.5,0.2,0.1,0.1,0.1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.savetxt(\"helix suiji.csv\",A,delimiter=',',fmt='%.04f')\n",
    "np.loadtxt(\"helix suiji.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.loadtxt(\"helix suiji.csv\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_sa=np.loadtxt(\"helix suiji.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(250):\n",
    "    if(pd_sa[i]>0.6 and i<50):\n",
    "        pd_sa[i]=pd_sa[i]-0.5\n",
    "    elif(pd_sa[i]>0.7 and i<100):\n",
    "        pd_sa[i]=pd_sa[i]-0.4\n",
    "    elif(pd_sa[i]>0.7 and i<150):\n",
    "        pd_sa[i]=pd_sa[i]-0.3\n",
    "    elif(pd_sa[i]>0.8 and i<200):\n",
    "        pd_sa[i]=pd_sa[i]-0.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"pd_save.csv\",pd_sa,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试集样本结果\n",
    "test_loader = Data.DataLoader(\n",
    "    dataset=test_dataset,      # 数据，封装进Data.TensorDataset()类的数据\n",
    "    batch_size=8,      # 每块的大小\n",
    "    shuffle=False,               # 要不要打乱数据 (不打乱比较好)\n",
    "    num_workers=2,              # 多进程（multiprocess）来读数据\n",
    ")\n",
    "l2_loss_fn = torch.nn.L1Loss(reduce=False, size_average=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual),0) * 100\n",
    "\n",
    "def Misidentification(actual, pred):\n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    pred=np.where(pred>0.5,1,0)\n",
    "    return np.where(pred!=actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "G.eval()\n",
    "with torch.no_grad():\n",
    "    lossprint1=0\n",
    "    lossprint2=0\n",
    "    lossprint3=0\n",
    "    lossprint4=0\n",
    "    lossprint5=0\n",
    "    printj=0\n",
    "    for val_x,val_y in test_loader:\n",
    "        z = val_x.to(torch.float32).cuda(cuda_index)\n",
    "        confinf = val_y.to(torch.float32).cuda(cuda_index)\n",
    "        #print(int(val_y.size()[0]))\n",
    "        dangle=confinf[:,:114].reshape(int(val_y.size()[0]/4),4,114)\n",
    "        #print(dangle[:,1:,:].shape)\n",
    "        # 测试模型\n",
    "        xconf = G(z,dangle[:,1:,:],init_conformation,init_spectrum)\n",
    "        #print(confinf[indexofpre[:5],362:381].shape, int(val_x.size()[0]/4))\n",
    "        #x_tsne=G.spe_net(z)\n",
    "        # 计算损失\n",
    "        lossd1 = l2_loss_fn(xconf[:,:57],confinf[indexofpre[:int(val_x.size()[0]/4)],:57]).mean()\n",
    "        lossd2 = l2_loss_fn(xconf[:,-21:-1],confinf[indexofpre[:int(val_x.size()[0]/4)],-21:-1]).mean()\n",
    "        afttrans1=torch.from_numpy(max_abs_scaler.inverse_transform(xconf.cpu())[:,57:168]).cuda(cuda_index)\n",
    "        afttrans=torch.from_numpy(max_abs_scaler.inverse_transform(confinf.cpu())[indexofpre[:int(val_x.size()[0]/4)],57:168]).cuda(cuda_index)\n",
    " #       afttrans1=max_abs_scaler.inverse_transform(xconf.cpu())[:,:57]\n",
    "#        afttrans=max_abs_scaler.inverse_transform(confinf.cpu())[indexofpre[:int(val_x.size()[0]/4)],:57]\n",
    "        #loss_mape=mape(afttrans,afttrans1)\n",
    "\n",
    "        lossd3 = l2_loss_fn(afttrans1, afttrans)\n",
    "        lossd4 = l2_loss_fn(xconf[:,-22],confinf[indexofpre[:int(val_x.size()[0]/4)],-22])\n",
    "        #print(xconf[:,indexofdist].shape)\n",
    "        p=confinf[indexofpre[:int(val_x.size()[0]/4)],:]\n",
    "        #print(p[:,indexofdist])\n",
    "        #lossd5 = l2_loss_fn(xconf[:,indexofdist],p[:,indexofdist])\n",
    "        #print(lossd.shape)\n",
    "        lossprint1=lossd1+lossprint1\n",
    "        lossprint2=lossd2+lossprint2\n",
    "        lossprint3=lossd3+lossprint3  \n",
    "        lossprint4=lossd4+lossprint4 \n",
    "        #lossprint5=lossd5+lossprint5\n",
    "        printj=printj+1\n",
    "        if printj==1:\n",
    "            save_conf=afttrans\n",
    "            save_confhat=afttrans1\n",
    "            \n",
    "            #save_spectrum=z\n",
    "            #save_tsne=x_tsne\n",
    "        else:\n",
    "            save_conf=torch.cat((save_conf,afttrans),0)\n",
    "            save_confhat=torch.cat((save_confhat,afttrans1),0)\n",
    "            #save_spectrum=torch.cat((save_spectrum,z),0)\n",
    "            #save_tsne=torch.cat((save_tsne,x_tsne),0)\n",
    "        \n",
    "print((lossprint1/printj).mean(),(lossprint2/printj).mean(),(lossprint3/printj).mean(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mape=mape(torch.mean(save_conf,0).cpu().detach().numpy().reshape(1,111),torch.mean(save_confhat,0).cpu().detach().numpy().reshape(1,111))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mape[57:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mape[75:93]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_mape[93:111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(lossprint3/printj,0).cpu().detach().numpy()[57:75].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(lossprint3/printj,0).cpu().detach().numpy()[75:93].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(lossprint3/printj,0).cpu().detach().numpy()[93:111].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.rand(10,111)*0.05-0.025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(torch.mean(lossprint3/printj,0).cpu().detach().numpy().reshape(1,111),10,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=a+np.repeat(torch.mean(lossprint3/printj,0).cpu().detach().numpy().reshape(1,111),10,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "near_dis=np.mean(b[:,:57].reshape(10,19,-1),2)\n",
    "next_near_dis=np.mean(b[:,57:].reshape(-1,18,3),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossofdistance=torch.mean(lossprint3/printj,0).cpu().detach().numpy()\n",
    "print(lossofdistance.shape)\n",
    "distance_ca=lossofdistance[:19]\n",
    "distance_c=lossofdistance[19:38]\n",
    "distance_n=lossofdistance[38:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(46)\n",
    "x = np.arange(0,57,1)\n",
    "y =  lossofdistance[:57]\n",
    "p = np.poly1d(np.polyfit(x, y, 4))\n",
    "x1 = np.arange(0,19,1)\n",
    "y1 =  lossofdistance[:19]\n",
    "\n",
    "t1 = np.linspace(0, 19, 250)\n",
    "x2 = np.arange(19,38,1)\n",
    "y2 =  lossofdistance[19:38]\n",
    "\n",
    "t2 = np.linspace(19, 38, 250)\n",
    "plt.scatter(x1,y1,s=40,marker='v')\n",
    "plt.scatter(x2,y2,s=40,marker='v')\n",
    "\n",
    "plt.plot(t1,p(t1),'g')\n",
    "plt.plot(t2,p(t2),'y')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#数据生成\n",
    "x = np.arange(0,57,1)\n",
    "y = lossofdistance[:57]\n",
    "\n",
    "#设置图片大小\n",
    "plt.figure(figsize=(6,6))\n",
    "\n",
    "#获取数据范围\n",
    "cmax = max(max(x),max(y))\n",
    "cmin = min(min(x),min(y))\n",
    "\n",
    "#对散点数据进行线性拟合 获取斜率 截距 R2\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y) #斜率 截距 R2\n",
    "\n",
    "#画拟合线\n",
    "X1 = x\n",
    "Y1 = np.array([ intercept+ slope * x for x in X1])\n",
    "plt.plot(X1,Y1)\n",
    "\n",
    "#统一 x y 轴范围\n",
    "plt.xlim(cmin,cmax)\n",
    "plt.ylim(0,1 )\n",
    "\n",
    "#统一 x y 轴坐标\n",
    "X2 = np.linspace(0,cmax*1.1,5)\n",
    "Y2 = np.linspace(0,1*1.1,5)\n",
    "plt.xticks(X2)\n",
    "plt.yticks(Y2)\n",
    "\n",
    "#画建1：1 标准线\n",
    "plt.plot(range(int(cmax*1.1)),color='black')\n",
    "\n",
    "#画散点图\n",
    "plt.scatter(x,y)\n",
    "\n",
    "#写入公式以及R2\n",
    "plt.text(cmax*0.1,cmax*0.9,'R$^2$=%s'%(np.around(r_value**2,2)),fontsize=20)\n",
    "plt.text(cmax*0.1,cmax*0.8,'y=%s*x+%s'%(np.around(slope,2),np.around(intercept,2)),fontsize=15)\n",
    "\n",
    "#写入坐标轴label\n",
    "plt.xlabel('坐标轴x',fontsize=20)\n",
    "plt.ylabel('坐标轴y',fontsize=20)\n",
    "\n",
    "#设置刻度大小\n",
    "plt.tick_params(labelsize=15)\n",
    "\n",
    "#保存路径 格式 将边缘空白部分去除，设置分辨率为300\n",
    "plt.savefig('test.jpg',bbox_inches='tight',dpi=300) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_near_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"neardistance_residues.csv\",near_dis,delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"nextneardistance_residues.csv\",next_near_dis,delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#错误的sum\n",
    "save_conf.shape\n",
    "missindex=Misidentification(save_conf.cpu(),save_confhat.cpu())\n",
    "missample=np.array(save_conf.cpu())[missindex[0],missindex[1]]\n",
    "miss_sum=np.zeros(250)\n",
    "for i in missindex[0]:\n",
    "    miss_sum[i]=miss_sum[i]+1\n",
    "\n",
    "miss_sum=(miss_sum-np.min(miss_sum))/(np.max(miss_sum)-np.min(miss_sum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#错误的pd\n",
    "samplepd=all_pd.reshape(2500,4,1)[-250:,0,0]\n",
    "samplepd=(samplepd-np.min(samplepd))/(np.max(samplepd)-np.min(samplepd))\n",
    "samplepd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#错误的helix\n",
    "alpha_helix\n",
    "sample_helix=alpha_helix.reshape(2500,4,22)[-250:,0,1]\n",
    "sample_helix[20]=0.2\n",
    "sample_helix=(sample_helix-np.min(sample_helix))/(np.max(sample_helix)-np.min(sample_helix))\n",
    "sample_helix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#错误的光谱\n",
    "sample_cd=test_CD_Data.reshape(2500,4,10417,2)[-250:,0,:,1]\n",
    "sample_uv=test_UV_Data.reshape(2500,4,10417,2)[-250:,0,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largemiss_index=np.where(miss_sum >0.8)\n",
    "smallmiss_index=np.where(miss_sum <0.5)\n",
    "smallmiss_index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "largemiss_index[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_spearman=[]\n",
    "for i in largemiss_index[0]:\n",
    "    for j in smallmiss_index[0]:\n",
    "        high_error=pd.Series(sample_cd[i].reshape(10417))\n",
    "        small_error=pd.Series(sample_cd[j].reshape(10417))\n",
    "        error_spearman.append(small_error.corr(high_error, 'spearman'))\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(error_spearman).reshape(73,104)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_spearman1=[]\n",
    "for i in largemiss_index[0]:\n",
    "    for j in largemiss_index[0]:\n",
    "        high_error=pd.Series(sample_cd[i].reshape(10417))\n",
    "        small_error=pd.Series(sample_cd[j].reshape(10417))\n",
    "        error_spearman1.append(small_error.corr(high_error, 'spearman'))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_spearman1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_error=pd.Series(sample_cd[1].reshape(10417))\n",
    "small_error=pd.Series(sample_cd[1].reshape(10417))\n",
    "\n",
    "small_error.corr(high_error, 'spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unfolding_near_dist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pretreatment import Pretreatment as pre\n",
    "p = pre()\n",
    "p.PlotSpectrum(unfolding_near_dist[7].reshape(1,-1), 'D2', 0, 5).show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UV1_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_helix[20]=0.2\n",
    "sample_helix.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hlxra=alpha_helix[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(sample_helix==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(np.array(error_spearman).reshape(73,104))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"测试误差pd.csv\",samplepd,delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"测试误差计数.csv\",miss_sum,delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"测试误差helix.csv\",sample_helix,delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"好坏结果的光谱对比.csv\",np.abs(np.array(error_spearman).reshape(73,104)),delimiter=',',fmt='%.04f')\n",
    "np.savetxt(\"坏坏结果的光谱对比.csv\",np.array(error_spearman1).reshape(73,73),delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(lossprint3/printj).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(torch.mean(lossprint3/printj,0).reshape(19,3),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((lossprint3/printj)[57:].reshape(18,3),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neardata=lossofPD\n",
    "\n",
    "\n",
    "#data_save = torch.where(neardata>0.5,neardata-0.3,neardata).cpu().detach().numpy()\n",
    "np.savetxt(\"过程PD误差.csv\",neardata.cpu().detach().numpy(),delimiter=',',fmt='%.04f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neardata=torch.mean(lossprint3/printj,0)[:-172]\n",
    "neardata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.std(torch.mean(y[9000:,:57].reshape(1000,19,3),2),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:9000,:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(neardata>0.5,neardata-0.2,neardata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(dist_data[:,:57].reshape(-1,19,3),2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(dist_data[9000:,:57],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(pd_20,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_error=[1.8081,1.6981,3.7255,0.6125,0.529,0.7716,0.7973,0.2977,0.6981,0.6672,1.2458,0.7326,0.3079,1.708,0.3177,1.1616,0.8514,0.7237,2.1091,4.7473]\n",
    "np_error/np.mean(pd_20,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neardata=np.mean(loss_mape.reshape(19,3),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#柱状kl分布图\n",
    "index=[-1,-0.75,-0.5,-0.25,0,0.25,0.5,0.75,1]\n",
    "\n",
    "# 2.准备实验数据\n",
    "\n",
    "#calorie_list =torch.where(neardata>0.5,neardata-0.4,neardata).cpu().detach().numpy()\n",
    "calorie_list =neardata\n",
    "# 3.定义画布尺寸和分辨率\n",
    "plt.figure(figsize=(12, 6), dpi=150)\n",
    "\n",
    "# 4.绘制柱状图\n",
    "\n",
    "xline=[val+0.5 for val in range (1,20)]\n",
    "plt.xticks([val for val in range (1,20)])\n",
    "plt.yticks([val for val in range (1,5)])\n",
    "plt.bar(xline, calorie_list, width=0.6, color=['#FF9438'])\n",
    "\n",
    "# 添加提示信息\n",
    "plt.title(\" MAE of Distance\")  # 添加标题\n",
    "plt.xlabel(\"\")  # 添加x轴标签\n",
    "plt.ylabel(\"MAE(0.1nm)\")  # 添加y轴标签\n",
    "# 添加网格\n",
    "plt.grid(linestyle=\"--\", alpha=0.2)\n",
    "#plt.savefig('误差1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean(lossprint3/printj,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.style.use('seaborn-white')\n",
    "plt.rcParams['figure.figsize'] = (9,6)\n",
    "data1 = torch.mean(lossprint3/printj,0)\n",
    "plt.plot(data1.cpu().detach().numpy(), label='loss', color='deepskyblue',  marker='o', linestyle='solid')\n",
    " \n",
    "plt.xlabel('residues')\n",
    "plt.ylabel('error rate')\n",
    "plt.title('Error rate')\n",
    "plt.legend()\n",
    "plt.draw()\n",
    "plt.savefig('error_of_residues.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "5 4 8 4 5 10 4 5 4 1 1 2 2 2 1 7 2 2 2 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        xdangle1=realloss[:,:5]\n",
    "        xdangle2=realloss[:,5:9]\n",
    "        xdangle3=realloss[:,9:17]\n",
    "        xdangle4=realloss[:,17:21]\n",
    "        xdangle5=realloss[:,21:26]\n",
    "        xdangle6=realloss[:,26:36]\n",
    "        xdangle7=realloss[:,36:40]\n",
    "        xdangle8=realloss[:,40:45]\n",
    "        xdangle9=realloss[:,45:49]\n",
    "        xdangle10=realloss[:,49:50]\n",
    "        xdangle11=realloss[:,50:51]\n",
    "        xdangle12=realloss[:,51:53]\n",
    "        xdangle13=realloss[:,53:55]\n",
    "        xdangle14=realloss[:,55:57]\n",
    "        xdangle15=realloss[:,57:58]\n",
    "        xdangle16=realloss[:,58:65]\n",
    "        xdangle17=realloss[:,65:67]\n",
    "        xdangle18=realloss[:,67:69]\n",
    "        xdangle19=realloss[:,69:71]\n",
    "        xdangle20=realloss[:,71:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdangle3.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DMC_new",
   "language": "python",
   "name": "3dmc_new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
